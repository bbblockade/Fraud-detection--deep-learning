{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "features_d2 = []\n",
    "labels_d2 = []\n",
    "# Open file for reading\n",
    "with open('domain2_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d2.append(obj['text'])\n",
    "        labels_d2.append(obj['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None)  \n",
    "\n",
    "# Fit and transform the data to text\n",
    "features_tfidf = tfidf.fit_transform(features_d2)\n",
    "label_d2 = np.array(labels_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the trained vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tfidf, labels_d2, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925;, score=0.353 total time=   9.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925;, score=0.339 total time=   9.1s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925;, score=0.350 total time=   9.2s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925;, score=0.346 total time=   9.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7852647356757848, learning_rate=0.013203027910561781, max_depth=27, min_child_samples=42, n_estimators=285, num_leaves=30, reg_alpha=0.875386340044103, reg_lambda=0.7290703968971941, scale_pos_weight=12, subsample=0.7511013826320925;, score=0.366 total time=   9.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181;, score=0.373 total time=  14.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181;, score=0.347 total time=  15.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181;, score=0.370 total time=  14.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181;, score=0.356 total time=  14.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9146665371880265, learning_rate=0.012771405219714892, max_depth=13, min_child_samples=59, n_estimators=458, num_leaves=41, reg_alpha=0.548998831258988, reg_lambda=0.035197468290328666, scale_pos_weight=12, subsample=0.896570910252181;, score=0.392 total time=  13.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606;, score=0.407 total time=   8.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606;, score=0.342 total time=   8.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606;, score=0.353 total time=   8.8s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606;, score=0.365 total time=   8.4s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8021398997201549, learning_rate=0.06821921864501336, max_depth=27, min_child_samples=47, n_estimators=215, num_leaves=35, reg_alpha=0.5803895993367254, reg_lambda=0.008086896284233648, scale_pos_weight=9, subsample=0.7204722269574606;, score=0.420 total time=   8.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964;, score=0.393 total time=  16.2s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964;, score=0.342 total time=  15.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964;, score=0.345 total time=  15.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964;, score=0.338 total time=  15.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7887662797587597, learning_rate=0.04094248701935149, max_depth=29, min_child_samples=60, n_estimators=536, num_leaves=29, reg_alpha=0.6082095570000399, reg_lambda=0.891001101830293, scale_pos_weight=6, subsample=0.8256501355747964;, score=0.405 total time=  15.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977;, score=0.343 total time=  44.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977;, score=0.267 total time=  44.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977;, score=0.305 total time=  45.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977;, score=0.273 total time=  44.2s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9777316467789237, learning_rate=0.015645541397478653, max_depth=30, min_child_samples=38, n_estimators=741, num_leaves=50, reg_alpha=0.7004944012147856, reg_lambda=0.21873226336234536, scale_pos_weight=3, subsample=0.7986142216836977;, score=0.341 total time=  44.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914;, score=0.380 total time=  28.2s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914;, score=0.301 total time=  32.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914;, score=0.341 total time=  30.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914;, score=0.318 total time=  30.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7807356383195609, learning_rate=0.030284758422572524, max_depth=21, min_child_samples=39, n_estimators=793, num_leaves=39, reg_alpha=0.9540802685819878, reg_lambda=0.4318483595425684, scale_pos_weight=6, subsample=0.7355242147787914;, score=0.368 total time=  30.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304;, score=0.383 total time=   8.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304;, score=0.351 total time=   8.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304;, score=0.376 total time=   8.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304;, score=0.362 total time=   8.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8570336413409161, learning_rate=0.02625552704088881, max_depth=11, min_child_samples=51, n_estimators=330, num_leaves=35, reg_alpha=0.8496100553162772, reg_lambda=0.008351307104059071, scale_pos_weight=12, subsample=0.9478751549290304;, score=0.394 total time=   8.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663;, score=0.342 total time=  42.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663;, score=0.288 total time=  42.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663;, score=0.306 total time=  43.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663;, score=0.289 total time=  42.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8538023597530678, learning_rate=0.04152428767623944, max_depth=24, min_child_samples=39, n_estimators=968, num_leaves=45, reg_alpha=0.2020529969506522, reg_lambda=0.7363327618035661, scale_pos_weight=7, subsample=0.702378414961663;, score=0.324 total time=  42.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675;, score=0.390 total time=   7.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675;, score=0.353 total time=   7.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675;, score=0.385 total time=   7.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675;, score=0.356 total time=   7.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.977032320056122, learning_rate=0.04550780899384349, max_depth=12, min_child_samples=46, n_estimators=243, num_leaves=41, reg_alpha=0.31927368200982337, reg_lambda=0.22858861170016814, scale_pos_weight=14, subsample=0.7066793277985675;, score=0.399 total time=   7.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607;, score=0.376 total time=  21.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607;, score=0.351 total time=  21.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607;, score=0.367 total time=  21.6s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607;, score=0.364 total time=  21.7s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9494429069761726, learning_rate=0.010566262295454234, max_depth=18, min_child_samples=49, n_estimators=630, num_leaves=39, reg_alpha=0.21288963918469034, reg_lambda=0.6846343456965398, scale_pos_weight=14, subsample=0.8666725677029607;, score=0.386 total time=  21.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7;, score=0.372 total time=   3.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7;, score=0.311 total time=   3.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7;, score=0.304 total time=   3.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7;, score=0.283 total time=   3.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7, learning_rate=0.1, max_depth=30, min_child_samples=50, n_estimators=100, num_leaves=39, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=3, subsample=0.7;, score=0.388 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643;, score=0.354 total time=   3.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643;, score=0.303 total time=   3.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643;, score=0.288 total time=   3.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643;, score=0.318 total time=   3.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9564983182583666, learning_rate=0.1, max_depth=13, min_child_samples=46, n_estimators=100, num_leaves=25, reg_alpha=0.2807359071001333, reg_lambda=0.0, scale_pos_weight=3, subsample=0.9931012074578643;, score=0.396 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384;, score=0.387 total time=   4.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384;, score=0.344 total time=   4.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384;, score=0.357 total time=   4.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384;, score=0.363 total time=   4.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8210502465823547, learning_rate=0.1, max_depth=10, min_child_samples=57, n_estimators=186, num_leaves=50, reg_alpha=0.8179914653001155, reg_lambda=0.0, scale_pos_weight=15, subsample=0.9338025123128384;, score=0.407 total time=   3.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147;, score=0.393 total time=  12.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147;, score=0.315 total time=  12.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147;, score=0.349 total time=  12.7s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147;, score=0.320 total time=  12.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8686704538298282, learning_rate=0.1, max_depth=25, min_child_samples=51, n_estimators=381, num_leaves=32, reg_alpha=0.3808809744517303, reg_lambda=0.7426510302411061, scale_pos_weight=15, subsample=0.7168448999891147;, score=0.380 total time=  12.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687;, score=0.391 total time=   3.2s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687;, score=0.350 total time=   3.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687;, score=0.363 total time=   3.1s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687;, score=0.372 total time=   3.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8599190271613508, learning_rate=0.011066957850900734, max_depth=25, min_child_samples=59, n_estimators=100, num_leaves=45, reg_alpha=0.4464084000253836, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7334310893618687;, score=0.389 total time=   2.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7;, score=0.401 total time=   3.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7;, score=0.348 total time=   3.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7;, score=0.353 total time=   3.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7;, score=0.370 total time=   3.4s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8509928534767928, learning_rate=0.01, max_depth=30, min_child_samples=35, n_estimators=100, num_leaves=38, reg_alpha=1.0, reg_lambda=0.8157269693554035, scale_pos_weight=12, subsample=0.7;, score=0.407 total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7;, score=0.315 total time=  29.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7;, score=0.271 total time=  30.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7;, score=0.296 total time=  29.2s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7;, score=0.266 total time=  29.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9094930577830397, learning_rate=0.1, max_depth=26, min_child_samples=36, n_estimators=1000, num_leaves=33, reg_alpha=1.0, reg_lambda=0.965841284316259, scale_pos_weight=8, subsample=0.7;, score=0.319 total time=  29.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0;, score=0.395 total time=   3.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0;, score=0.340 total time=   3.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0;, score=0.361 total time=   3.1s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0;, score=0.372 total time=   3.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, min_child_samples=60, n_estimators=100, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=14, subsample=1.0;, score=0.401 total time=   3.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0;, score=0.382 total time=   3.7s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0;, score=0.356 total time=   3.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0;, score=0.364 total time=   3.7s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0;, score=0.361 total time=   3.7s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8786322255565778, learning_rate=0.033894389979932715, max_depth=10, min_child_samples=43, n_estimators=100, num_leaves=50, reg_alpha=0.41972498312260276, reg_lambda=0.0, scale_pos_weight=10, subsample=1.0;, score=0.390 total time=   3.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794;, score=0.404 total time=   2.7s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794;, score=0.351 total time=   2.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794;, score=0.384 total time=   2.8s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794;, score=0.377 total time=   2.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8125536568762955, learning_rate=0.06298519260334282, max_depth=16, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=0.22405219714994692, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9851496386121794;, score=0.413 total time=   2.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691;, score=0.413 total time=  32.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691;, score=0.353 total time=  33.1s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691;, score=0.371 total time=  34.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691;, score=0.366 total time=  32.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.019955833339693613, max_depth=22, min_child_samples=60, n_estimators=1000, num_leaves=30, reg_alpha=0.5005662363313832, reg_lambda=0.0, scale_pos_weight=15, subsample=0.8468453463641691;, score=0.412 total time=  32.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7;, score=0.356 total time=  23.2s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7;, score=0.337 total time=  23.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7;, score=0.353 total time=  24.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7;, score=0.346 total time=  23.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=22, min_child_samples=35, n_estimators=649, num_leaves=28, reg_alpha=0.7201534828061182, reg_lambda=0.0, scale_pos_weight=15, subsample=0.7;, score=0.363 total time=  23.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287;, score=0.411 total time=  15.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287;, score=0.355 total time=  15.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287;, score=0.362 total time=  15.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287;, score=0.361 total time=  15.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7198689092457308, learning_rate=0.031813292746678073, max_depth=16, min_child_samples=60, n_estimators=672, num_leaves=27, reg_alpha=0.17165809866732668, reg_lambda=0.0, scale_pos_weight=9, subsample=0.8106636136395287;, score=0.424 total time=  15.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546;, score=0.368 total time=   3.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546;, score=0.335 total time=   3.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546;, score=0.344 total time=   3.6s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546;, score=0.352 total time=   3.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01498681000230652, max_depth=11, min_child_samples=35, n_estimators=100, num_leaves=37, reg_alpha=0.9553881056250761, reg_lambda=0.8705037283734878, scale_pos_weight=13, subsample=0.9080491639710546;, score=0.379 total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244;, score=0.372 total time=   3.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244;, score=0.342 total time=   3.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244;, score=0.349 total time=   3.1s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244;, score=0.357 total time=   3.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8388289484380329, learning_rate=0.01141377658911389, max_depth=15, min_child_samples=35, n_estimators=100, num_leaves=27, reg_alpha=0.7728250115616073, reg_lambda=0.0, scale_pos_weight=15, subsample=0.993912427070244;, score=0.372 total time=   3.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485;, score=0.323 total time=  24.7s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485;, score=0.282 total time=  25.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485;, score=0.297 total time=  26.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485;, score=0.304 total time=  25.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7, learning_rate=0.048038805406249704, max_depth=16, min_child_samples=60, n_estimators=1000, num_leaves=43, reg_alpha=0.7484663312072173, reg_lambda=0.0, scale_pos_weight=5, subsample=0.7046599231566485;, score=0.346 total time=  25.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216;, score=0.379 total time=   2.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216;, score=0.339 total time=   2.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216;, score=0.342 total time=   2.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216;, score=0.353 total time=   2.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8422067812481854, learning_rate=0.01, max_depth=15, min_child_samples=60, n_estimators=100, num_leaves=25, reg_alpha=1.0, reg_lambda=1.0, scale_pos_weight=10, subsample=0.8133256955027216;, score=0.400 total time=   2.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987;, score=0.425 total time=  16.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987;, score=0.367 total time=  16.8s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987;, score=0.388 total time=  17.1s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987;, score=0.389 total time=  16.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7234310885166573, learning_rate=0.016423885345104958, max_depth=23, min_child_samples=60, n_estimators=470, num_leaves=50, reg_alpha=0.30421732656825395, reg_lambda=0.0, scale_pos_weight=8, subsample=0.9344694754621987;, score=0.431 total time=  16.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0;, score=0.406 total time=   7.5s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0;, score=0.361 total time=   7.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0;, score=0.374 total time=   7.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0;, score=0.335 total time=   7.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7873124075404497, learning_rate=0.060008914775750606, max_depth=13, min_child_samples=60, n_estimators=391, num_leaves=50, reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=8, subsample=1.0;, score=0.389 total time=   7.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0;, score=0.371 total time=  16.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0;, score=0.348 total time=  17.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0;, score=0.364 total time=  16.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0;, score=0.355 total time=  16.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_samples=60, n_estimators=1000, num_leaves=50, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=15, subsample=1.0;, score=0.379 total time=  16.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2,\n",
       "                                       objective=&#x27;binary&#x27;, verbose=-1),\n",
       "              n_iter=30, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;colsample_bytree&#x27;: (0.7, 1.0),\n",
       "                             &#x27;learning_rate&#x27;: (0.01, 0.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (10, 30),\n",
       "                             &#x27;min_child_samples&#x27;: (35, 60),\n",
       "                             &#x27;n_estimators&#x27;: (100, 1000),\n",
       "                             &#x27;num_leaves&#x27;: (25, 50), &#x27;reg_alpha&#x27;: (0.0, 1.0),\n",
       "                             &#x27;reg_lambda&#x27;: (0.0, 1.0),\n",
       "                             &#x27;scale_pos_weight&#x27;: (3, 15),\n",
       "                             &#x27;subsample&#x27;: (0.7, 1.0)},\n",
       "              verbose=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2,\n",
       "                                       objective=&#x27;binary&#x27;, verbose=-1),\n",
       "              n_iter=30, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;colsample_bytree&#x27;: (0.7, 1.0),\n",
       "                             &#x27;learning_rate&#x27;: (0.01, 0.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (10, 30),\n",
       "                             &#x27;min_child_samples&#x27;: (35, 60),\n",
       "                             &#x27;n_estimators&#x27;: (100, 1000),\n",
       "                             &#x27;num_leaves&#x27;: (25, 50), &#x27;reg_alpha&#x27;: (0.0, 1.0),\n",
       "                             &#x27;reg_lambda&#x27;: (0.0, 1.0),\n",
       "                             &#x27;scale_pos_weight&#x27;: (3, 15),\n",
       "                             &#x27;subsample&#x27;: (0.7, 1.0)},\n",
       "              verbose=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2, objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2, objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric='binary_error', n_jobs=2,\n",
       "                                       objective='binary', verbose=-1),\n",
       "              n_iter=30, scoring='f1',\n",
       "              search_spaces={'colsample_bytree': (0.7, 1.0),\n",
       "                             'learning_rate': (0.01, 0.1, 'log-uniform'),\n",
       "                             'max_depth': (10, 30),\n",
       "                             'min_child_samples': (35, 60),\n",
       "                             'n_estimators': (100, 1000),\n",
       "                             'num_leaves': (25, 50), 'reg_alpha': (0.0, 1.0),\n",
       "                             'reg_lambda': (0.0, 1.0),\n",
       "                             'scale_pos_weight': (3, 15),\n",
       "                             'subsample': (0.7, 1.0)},\n",
       "              verbose=100)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the simplified hyperparameter configuration space\n",
    "param_space = {\n",
    "    'num_leaves': (25, 50),\n",
    "    'max_depth': (10, 30),\n",
    "    'min_child_samples': (35, 60),\n",
    "    'subsample': (0.7, 1.0),\n",
    "    'colsample_bytree': (0.7, 1.0),\n",
    "    'scale_pos_weight': (3, 15),\n",
    "    'learning_rate': (0.01, 0.1, 'log-uniform'),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'reg_alpha': (0.0, 1.0),\n",
    "    'reg_lambda': (0.0, 1.0),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_error',\n",
    "        n_jobs=2,\n",
    "        verbose= -1\n",
    "    ),\n",
    "    search_spaces=param_space,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    n_iter=30,\n",
    "    verbose=100,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "opt.fit(features_tfidf, labels_d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3997561637815428"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bytree', 0.7234310885166573),\n",
       "             ('learning_rate', 0.016423885345104958),\n",
       "             ('max_depth', 23),\n",
       "             ('min_child_samples', 60),\n",
       "             ('n_estimators', 470),\n",
       "             ('num_leaves', 50),\n",
       "             ('reg_alpha', 0.30421732656825395),\n",
       "             ('reg_lambda', 0.0),\n",
       "             ('scale_pos_weight', 8),\n",
       "             ('subsample', 0.9344694754621987)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x23897242c70>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = opt.best_params_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_params['scale_pos_weight'] = 7.5\n",
    "\n",
    "# Manually train a model using the best params\n",
    "clf = lgb.LGBMClassifier(**best_params)\n",
    "clf.fit(features_tfidf, labels_d2)\n",
    "\n",
    "\n",
    "\n",
    "# Save model\n",
    "clf.booster_.save_model('domain2_model.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15120917, 0.35533517, 0.28387424, ..., 0.65429229, 0.64706411,\n",
       "       0.5465303 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7751677852348994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"precision:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5504587155963303"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162112\n",
      "[LightGBM] [Info] Number of data points in the train set: 11920, number of used features: 2171\n",
      "[LightGBM] [Info] Start training from score 0.143792\n",
      "[1]\tvalid_0's l2: 0.12454\n",
      "[2]\tvalid_0's l2: 0.124207\n",
      "[3]\tvalid_0's l2: 0.123862\n",
      "[4]\tvalid_0's l2: 0.123668\n",
      "[5]\tvalid_0's l2: 0.12336\n",
      "[6]\tvalid_0's l2: 0.123078\n",
      "[7]\tvalid_0's l2: 0.122752\n",
      "[8]\tvalid_0's l2: 0.122563\n",
      "[9]\tvalid_0's l2: 0.122279\n",
      "[10]\tvalid_0's l2: 0.122182\n",
      "[11]\tvalid_0's l2: 0.121908\n",
      "[12]\tvalid_0's l2: 0.121738\n",
      "[13]\tvalid_0's l2: 0.12146\n",
      "[14]\tvalid_0's l2: 0.121204\n",
      "[15]\tvalid_0's l2: 0.120948\n",
      "[16]\tvalid_0's l2: 0.120745\n",
      "[17]\tvalid_0's l2: 0.120582\n",
      "[18]\tvalid_0's l2: 0.120358\n",
      "[19]\tvalid_0's l2: 0.120078\n",
      "[20]\tvalid_0's l2: 0.11981\n",
      "[21]\tvalid_0's l2: 0.119687\n",
      "[22]\tvalid_0's l2: 0.119463\n",
      "[23]\tvalid_0's l2: 0.119307\n",
      "[24]\tvalid_0's l2: 0.119097\n",
      "[25]\tvalid_0's l2: 0.118855\n",
      "[26]\tvalid_0's l2: 0.118598\n",
      "[27]\tvalid_0's l2: 0.118385\n",
      "[28]\tvalid_0's l2: 0.118179\n",
      "[29]\tvalid_0's l2: 0.117946\n",
      "[30]\tvalid_0's l2: 0.11778\n",
      "[31]\tvalid_0's l2: 0.117572\n",
      "[32]\tvalid_0's l2: 0.117458\n",
      "[33]\tvalid_0's l2: 0.117304\n",
      "[34]\tvalid_0's l2: 0.117177\n",
      "[35]\tvalid_0's l2: 0.117025\n",
      "[36]\tvalid_0's l2: 0.116894\n",
      "[37]\tvalid_0's l2: 0.11672\n",
      "[38]\tvalid_0's l2: 0.116566\n",
      "[39]\tvalid_0's l2: 0.116405\n",
      "[40]\tvalid_0's l2: 0.11621\n",
      "[41]\tvalid_0's l2: 0.11608\n",
      "[42]\tvalid_0's l2: 0.115921\n",
      "[43]\tvalid_0's l2: 0.115785\n",
      "[44]\tvalid_0's l2: 0.115726\n",
      "[45]\tvalid_0's l2: 0.115599\n",
      "[46]\tvalid_0's l2: 0.115465\n",
      "[47]\tvalid_0's l2: 0.115369\n",
      "[48]\tvalid_0's l2: 0.115245\n",
      "[49]\tvalid_0's l2: 0.115176\n",
      "[50]\tvalid_0's l2: 0.114999\n",
      "[51]\tvalid_0's l2: 0.114858\n",
      "[52]\tvalid_0's l2: 0.114801\n",
      "[53]\tvalid_0's l2: 0.11467\n",
      "[54]\tvalid_0's l2: 0.114602\n",
      "[55]\tvalid_0's l2: 0.114458\n",
      "[56]\tvalid_0's l2: 0.114299\n",
      "[57]\tvalid_0's l2: 0.114184\n",
      "[58]\tvalid_0's l2: 0.114117\n",
      "[59]\tvalid_0's l2: 0.114082\n",
      "[60]\tvalid_0's l2: 0.113985\n",
      "[61]\tvalid_0's l2: 0.113878\n",
      "[62]\tvalid_0's l2: 0.113785\n",
      "[63]\tvalid_0's l2: 0.113705\n",
      "[64]\tvalid_0's l2: 0.113595\n",
      "[65]\tvalid_0's l2: 0.1135\n",
      "[66]\tvalid_0's l2: 0.113375\n",
      "[67]\tvalid_0's l2: 0.113313\n",
      "[68]\tvalid_0's l2: 0.113223\n",
      "[69]\tvalid_0's l2: 0.11314\n",
      "[70]\tvalid_0's l2: 0.113056\n",
      "[71]\tvalid_0's l2: 0.112965\n",
      "[72]\tvalid_0's l2: 0.112872\n",
      "[73]\tvalid_0's l2: 0.112764\n",
      "[74]\tvalid_0's l2: 0.112632\n",
      "[75]\tvalid_0's l2: 0.112623\n",
      "[76]\tvalid_0's l2: 0.112501\n",
      "[77]\tvalid_0's l2: 0.112413\n",
      "[78]\tvalid_0's l2: 0.112343\n",
      "[79]\tvalid_0's l2: 0.112239\n",
      "[80]\tvalid_0's l2: 0.112179\n",
      "[81]\tvalid_0's l2: 0.112103\n",
      "[82]\tvalid_0's l2: 0.112002\n",
      "[83]\tvalid_0's l2: 0.111927\n",
      "[84]\tvalid_0's l2: 0.11184\n",
      "[85]\tvalid_0's l2: 0.111764\n",
      "[86]\tvalid_0's l2: 0.111746\n",
      "[87]\tvalid_0's l2: 0.111667\n",
      "[88]\tvalid_0's l2: 0.111624\n",
      "[89]\tvalid_0's l2: 0.111596\n",
      "[90]\tvalid_0's l2: 0.11152\n",
      "[91]\tvalid_0's l2: 0.111484\n",
      "[92]\tvalid_0's l2: 0.111412\n",
      "[93]\tvalid_0's l2: 0.11137\n",
      "[94]\tvalid_0's l2: 0.111344\n",
      "[95]\tvalid_0's l2: 0.111269\n",
      "[96]\tvalid_0's l2: 0.111204\n",
      "[97]\tvalid_0's l2: 0.111156\n",
      "[98]\tvalid_0's l2: 0.111128\n",
      "[99]\tvalid_0's l2: 0.111076\n",
      "[100]\tvalid_0's l2: 0.111061\n",
      "[101]\tvalid_0's l2: 0.11102\n",
      "[102]\tvalid_0's l2: 0.11099\n",
      "[103]\tvalid_0's l2: 0.110942\n",
      "[104]\tvalid_0's l2: 0.110889\n",
      "[105]\tvalid_0's l2: 0.110827\n",
      "[106]\tvalid_0's l2: 0.110769\n",
      "[107]\tvalid_0's l2: 0.110685\n",
      "[108]\tvalid_0's l2: 0.110639\n",
      "[109]\tvalid_0's l2: 0.110576\n",
      "[110]\tvalid_0's l2: 0.110561\n",
      "[111]\tvalid_0's l2: 0.110511\n",
      "[112]\tvalid_0's l2: 0.110463\n",
      "[113]\tvalid_0's l2: 0.110434\n",
      "[114]\tvalid_0's l2: 0.110378\n",
      "[115]\tvalid_0's l2: 0.110337\n",
      "[116]\tvalid_0's l2: 0.11031\n",
      "[117]\tvalid_0's l2: 0.110253\n",
      "[118]\tvalid_0's l2: 0.11018\n",
      "[119]\tvalid_0's l2: 0.110139\n",
      "[120]\tvalid_0's l2: 0.110077\n",
      "[121]\tvalid_0's l2: 0.110043\n",
      "[122]\tvalid_0's l2: 0.109964\n",
      "[123]\tvalid_0's l2: 0.109943\n",
      "[124]\tvalid_0's l2: 0.109912\n",
      "[125]\tvalid_0's l2: 0.109874\n",
      "[126]\tvalid_0's l2: 0.109823\n",
      "[127]\tvalid_0's l2: 0.109784\n",
      "[128]\tvalid_0's l2: 0.109731\n",
      "[129]\tvalid_0's l2: 0.10971\n",
      "[130]\tvalid_0's l2: 0.109703\n",
      "[131]\tvalid_0's l2: 0.109628\n",
      "[132]\tvalid_0's l2: 0.109598\n",
      "[133]\tvalid_0's l2: 0.109571\n",
      "[134]\tvalid_0's l2: 0.109548\n",
      "[135]\tvalid_0's l2: 0.109531\n",
      "[136]\tvalid_0's l2: 0.109505\n",
      "[137]\tvalid_0's l2: 0.109493\n",
      "[138]\tvalid_0's l2: 0.109473\n",
      "[139]\tvalid_0's l2: 0.109432\n",
      "[140]\tvalid_0's l2: 0.109403\n",
      "[141]\tvalid_0's l2: 0.109362\n",
      "[142]\tvalid_0's l2: 0.109357\n",
      "[143]\tvalid_0's l2: 0.109315\n",
      "[144]\tvalid_0's l2: 0.109293\n",
      "[145]\tvalid_0's l2: 0.109251\n",
      "[146]\tvalid_0's l2: 0.109226\n",
      "[147]\tvalid_0's l2: 0.109196\n",
      "[148]\tvalid_0's l2: 0.109172\n",
      "[149]\tvalid_0's l2: 0.109112\n",
      "[150]\tvalid_0's l2: 0.109081\n",
      "[151]\tvalid_0's l2: 0.109052\n",
      "[152]\tvalid_0's l2: 0.109046\n",
      "[153]\tvalid_0's l2: 0.109009\n",
      "[154]\tvalid_0's l2: 0.108977\n",
      "[155]\tvalid_0's l2: 0.108947\n",
      "[156]\tvalid_0's l2: 0.10892\n",
      "[157]\tvalid_0's l2: 0.108872\n",
      "[158]\tvalid_0's l2: 0.108858\n",
      "[159]\tvalid_0's l2: 0.108824\n",
      "[160]\tvalid_0's l2: 0.108796\n",
      "[161]\tvalid_0's l2: 0.108751\n",
      "[162]\tvalid_0's l2: 0.108736\n",
      "[163]\tvalid_0's l2: 0.108721\n",
      "[164]\tvalid_0's l2: 0.108688\n",
      "[165]\tvalid_0's l2: 0.108636\n",
      "[166]\tvalid_0's l2: 0.108631\n",
      "[167]\tvalid_0's l2: 0.108595\n",
      "[168]\tvalid_0's l2: 0.10859\n",
      "[169]\tvalid_0's l2: 0.108587\n",
      "[170]\tvalid_0's l2: 0.108578\n",
      "[171]\tvalid_0's l2: 0.108556\n",
      "[172]\tvalid_0's l2: 0.108518\n",
      "[173]\tvalid_0's l2: 0.108488\n",
      "[174]\tvalid_0's l2: 0.108445\n",
      "[175]\tvalid_0's l2: 0.10842\n",
      "[176]\tvalid_0's l2: 0.108396\n",
      "[177]\tvalid_0's l2: 0.108357\n",
      "[178]\tvalid_0's l2: 0.108319\n",
      "[179]\tvalid_0's l2: 0.108296\n",
      "[180]\tvalid_0's l2: 0.108281\n",
      "[181]\tvalid_0's l2: 0.108235\n",
      "[182]\tvalid_0's l2: 0.108203\n",
      "[183]\tvalid_0's l2: 0.108179\n",
      "[184]\tvalid_0's l2: 0.108161\n",
      "[185]\tvalid_0's l2: 0.108159\n",
      "[186]\tvalid_0's l2: 0.10814\n",
      "[187]\tvalid_0's l2: 0.108121\n",
      "[188]\tvalid_0's l2: 0.108092\n",
      "[189]\tvalid_0's l2: 0.108047\n",
      "[190]\tvalid_0's l2: 0.108023\n",
      "[191]\tvalid_0's l2: 0.107995\n",
      "[192]\tvalid_0's l2: 0.107977\n",
      "[193]\tvalid_0's l2: 0.107975\n",
      "[194]\tvalid_0's l2: 0.107964\n",
      "[195]\tvalid_0's l2: 0.107951\n",
      "[196]\tvalid_0's l2: 0.107928\n",
      "[197]\tvalid_0's l2: 0.107936\n",
      "[198]\tvalid_0's l2: 0.107928\n",
      "[199]\tvalid_0's l2: 0.10793\n",
      "[200]\tvalid_0's l2: 0.107897\n",
      "[201]\tvalid_0's l2: 0.107878\n",
      "[202]\tvalid_0's l2: 0.107852\n",
      "[203]\tvalid_0's l2: 0.107873\n",
      "[204]\tvalid_0's l2: 0.107845\n",
      "[205]\tvalid_0's l2: 0.107808\n",
      "[206]\tvalid_0's l2: 0.107771\n",
      "[207]\tvalid_0's l2: 0.107781\n",
      "[208]\tvalid_0's l2: 0.10776\n",
      "[209]\tvalid_0's l2: 0.107751\n",
      "[210]\tvalid_0's l2: 0.107705\n",
      "[211]\tvalid_0's l2: 0.107692\n",
      "[212]\tvalid_0's l2: 0.107719\n",
      "[213]\tvalid_0's l2: 0.107713\n",
      "[214]\tvalid_0's l2: 0.107687\n",
      "[215]\tvalid_0's l2: 0.107655\n",
      "[216]\tvalid_0's l2: 0.107658\n",
      "[217]\tvalid_0's l2: 0.107654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[218]\tvalid_0's l2: 0.107627\n",
      "[219]\tvalid_0's l2: 0.107614\n",
      "[220]\tvalid_0's l2: 0.107578\n",
      "[221]\tvalid_0's l2: 0.107557\n",
      "[222]\tvalid_0's l2: 0.107557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[223]\tvalid_0's l2: 0.107571\n",
      "[224]\tvalid_0's l2: 0.107566\n",
      "[225]\tvalid_0's l2: 0.107518\n",
      "[226]\tvalid_0's l2: 0.107494\n",
      "[227]\tvalid_0's l2: 0.107486\n",
      "[228]\tvalid_0's l2: 0.107443\n",
      "[229]\tvalid_0's l2: 0.107433\n",
      "[230]\tvalid_0's l2: 0.107446\n",
      "[231]\tvalid_0's l2: 0.107438\n",
      "[232]\tvalid_0's l2: 0.107398\n",
      "[233]\tvalid_0's l2: 0.107375\n",
      "[234]\tvalid_0's l2: 0.107358\n",
      "[235]\tvalid_0's l2: 0.107332\n",
      "[236]\tvalid_0's l2: 0.10732\n",
      "[237]\tvalid_0's l2: 0.107312\n",
      "[238]\tvalid_0's l2: 0.107295\n",
      "[239]\tvalid_0's l2: 0.107283\n",
      "[240]\tvalid_0's l2: 0.107281\n",
      "[241]\tvalid_0's l2: 0.107249\n",
      "[242]\tvalid_0's l2: 0.107244\n",
      "[243]\tvalid_0's l2: 0.107234\n",
      "[244]\tvalid_0's l2: 0.107246\n",
      "[245]\tvalid_0's l2: 0.107233\n",
      "[246]\tvalid_0's l2: 0.107234\n",
      "[247]\tvalid_0's l2: 0.107214\n",
      "[248]\tvalid_0's l2: 0.107204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[249]\tvalid_0's l2: 0.107205\n",
      "[250]\tvalid_0's l2: 0.107213\n",
      "[251]\tvalid_0's l2: 0.107217\n",
      "[252]\tvalid_0's l2: 0.107203\n",
      "[253]\tvalid_0's l2: 0.107185\n",
      "[254]\tvalid_0's l2: 0.107172\n",
      "[255]\tvalid_0's l2: 0.107182\n",
      "[256]\tvalid_0's l2: 0.107179\n",
      "[257]\tvalid_0's l2: 0.107159\n",
      "[258]\tvalid_0's l2: 0.107155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[259]\tvalid_0's l2: 0.107172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[260]\tvalid_0's l2: 0.107171\n",
      "[261]\tvalid_0's l2: 0.107158\n",
      "[262]\tvalid_0's l2: 0.107147\n",
      "[263]\tvalid_0's l2: 0.107132\n",
      "[264]\tvalid_0's l2: 0.107118\n",
      "[265]\tvalid_0's l2: 0.107104\n",
      "[266]\tvalid_0's l2: 0.107088\n",
      "[267]\tvalid_0's l2: 0.107057\n",
      "[268]\tvalid_0's l2: 0.107063\n",
      "[269]\tvalid_0's l2: 0.107059\n",
      "[270]\tvalid_0's l2: 0.107064\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[271]\tvalid_0's l2: 0.107047\n",
      "[272]\tvalid_0's l2: 0.107032\n",
      "[273]\tvalid_0's l2: 0.107016\n",
      "[274]\tvalid_0's l2: 0.107009\n",
      "[275]\tvalid_0's l2: 0.107013\n",
      "[276]\tvalid_0's l2: 0.107023\n",
      "[277]\tvalid_0's l2: 0.107017\n",
      "[278]\tvalid_0's l2: 0.106998\n",
      "[279]\tvalid_0's l2: 0.106973\n",
      "[280]\tvalid_0's l2: 0.106966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[281]\tvalid_0's l2: 0.10697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[282]\tvalid_0's l2: 0.10697\n",
      "[283]\tvalid_0's l2: 0.106958\n",
      "[284]\tvalid_0's l2: 0.106949\n",
      "[285]\tvalid_0's l2: 0.106939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[286]\tvalid_0's l2: 0.106933\n",
      "[287]\tvalid_0's l2: 0.106928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[288]\tvalid_0's l2: 0.106923\n",
      "[289]\tvalid_0's l2: 0.106922\n",
      "[290]\tvalid_0's l2: 0.106914\n",
      "[291]\tvalid_0's l2: 0.106906\n",
      "[292]\tvalid_0's l2: 0.106893\n",
      "[293]\tvalid_0's l2: 0.106888\n",
      "[294]\tvalid_0's l2: 0.106887\n",
      "[295]\tvalid_0's l2: 0.106902\n",
      "[296]\tvalid_0's l2: 0.106919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[297]\tvalid_0's l2: 0.106913\n",
      "[298]\tvalid_0's l2: 0.106902\n",
      "[299]\tvalid_0's l2: 0.106872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's l2: 0.10687\n",
      "[301]\tvalid_0's l2: 0.106868\n",
      "[302]\tvalid_0's l2: 0.106863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[303]\tvalid_0's l2: 0.106872\n",
      "[304]\tvalid_0's l2: 0.10687\n",
      "[305]\tvalid_0's l2: 0.106857\n",
      "[306]\tvalid_0's l2: 0.106845\n",
      "[307]\tvalid_0's l2: 0.106838\n",
      "[308]\tvalid_0's l2: 0.106832\n",
      "[309]\tvalid_0's l2: 0.106808\n",
      "[310]\tvalid_0's l2: 0.106802\n",
      "[311]\tvalid_0's l2: 0.106803\n",
      "[312]\tvalid_0's l2: 0.106792\n",
      "[313]\tvalid_0's l2: 0.106773\n",
      "[314]\tvalid_0's l2: 0.106781\n",
      "[315]\tvalid_0's l2: 0.106796\n",
      "[316]\tvalid_0's l2: 0.106809\n",
      "[317]\tvalid_0's l2: 0.1068\n",
      "[318]\tvalid_0's l2: 0.106802\n",
      "[319]\tvalid_0's l2: 0.106797\n",
      "[320]\tvalid_0's l2: 0.106809\n",
      "[321]\tvalid_0's l2: 0.106796\n",
      "[322]\tvalid_0's l2: 0.106769\n",
      "[323]\tvalid_0's l2: 0.106776\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[324]\tvalid_0's l2: 0.106766\n",
      "[325]\tvalid_0's l2: 0.106744\n",
      "[326]\tvalid_0's l2: 0.106724\n",
      "[327]\tvalid_0's l2: 0.10672\n",
      "[328]\tvalid_0's l2: 0.106709\n",
      "[329]\tvalid_0's l2: 0.106682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\tvalid_0's l2: 0.106673\n",
      "[331]\tvalid_0's l2: 0.106673\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[332]\tvalid_0's l2: 0.106671\n",
      "[333]\tvalid_0's l2: 0.106658\n",
      "[334]\tvalid_0's l2: 0.106645\n",
      "[335]\tvalid_0's l2: 0.106646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[336]\tvalid_0's l2: 0.106655\n",
      "[337]\tvalid_0's l2: 0.106656\n",
      "[338]\tvalid_0's l2: 0.106638\n",
      "[339]\tvalid_0's l2: 0.106615\n",
      "[340]\tvalid_0's l2: 0.106626\n",
      "[341]\tvalid_0's l2: 0.106608\n",
      "[342]\tvalid_0's l2: 0.106602\n",
      "[343]\tvalid_0's l2: 0.106578\n",
      "[344]\tvalid_0's l2: 0.106563\n",
      "[345]\tvalid_0's l2: 0.106558\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[346]\tvalid_0's l2: 0.106562\n",
      "[347]\tvalid_0's l2: 0.106552\n",
      "[348]\tvalid_0's l2: 0.106547\n",
      "[349]\tvalid_0's l2: 0.106548\n",
      "[350]\tvalid_0's l2: 0.106528\n",
      "[351]\tvalid_0's l2: 0.106532\n",
      "[352]\tvalid_0's l2: 0.106525\n",
      "[353]\tvalid_0's l2: 0.10652\n",
      "[354]\tvalid_0's l2: 0.106532\n",
      "[355]\tvalid_0's l2: 0.106521\n",
      "[356]\tvalid_0's l2: 0.106506\n",
      "[357]\tvalid_0's l2: 0.10651\n",
      "[358]\tvalid_0's l2: 0.106513\n",
      "[359]\tvalid_0's l2: 0.1065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[360]\tvalid_0's l2: 0.106497\n",
      "[361]\tvalid_0's l2: 0.106486\n",
      "[362]\tvalid_0's l2: 0.106472\n",
      "[363]\tvalid_0's l2: 0.106457\n",
      "[364]\tvalid_0's l2: 0.106446\n",
      "[365]\tvalid_0's l2: 0.106423\n",
      "[366]\tvalid_0's l2: 0.106411\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[367]\tvalid_0's l2: 0.106402\n",
      "[368]\tvalid_0's l2: 0.106398\n",
      "[369]\tvalid_0's l2: 0.106402\n",
      "[370]\tvalid_0's l2: 0.106403\n",
      "[371]\tvalid_0's l2: 0.106395\n",
      "[372]\tvalid_0's l2: 0.106393\n",
      "[373]\tvalid_0's l2: 0.106391\n",
      "[374]\tvalid_0's l2: 0.106396\n",
      "[375]\tvalid_0's l2: 0.106391\n",
      "[376]\tvalid_0's l2: 0.106373\n",
      "[377]\tvalid_0's l2: 0.106387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[378]\tvalid_0's l2: 0.106365\n",
      "[379]\tvalid_0's l2: 0.106345\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\tvalid_0's l2: 0.106336\n",
      "[381]\tvalid_0's l2: 0.106312\n",
      "[382]\tvalid_0's l2: 0.106303\n",
      "[383]\tvalid_0's l2: 0.106299\n",
      "[384]\tvalid_0's l2: 0.106294\n",
      "[385]\tvalid_0's l2: 0.106297\n",
      "[386]\tvalid_0's l2: 0.106298\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[387]\tvalid_0's l2: 0.1063\n",
      "[388]\tvalid_0's l2: 0.106295\n",
      "[389]\tvalid_0's l2: 0.106275\n",
      "[390]\tvalid_0's l2: 0.106258\n",
      "[391]\tvalid_0's l2: 0.106246\n",
      "[392]\tvalid_0's l2: 0.106232\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[393]\tvalid_0's l2: 0.106228\n",
      "[394]\tvalid_0's l2: 0.106233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[395]\tvalid_0's l2: 0.106237\n",
      "[396]\tvalid_0's l2: 0.106232\n",
      "[397]\tvalid_0's l2: 0.106235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[398]\tvalid_0's l2: 0.106237\n",
      "[399]\tvalid_0's l2: 0.10624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's l2: 0.106238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[401]\tvalid_0's l2: 0.106245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[402]\tvalid_0's l2: 0.106244\n",
      "[403]\tvalid_0's l2: 0.106252\n",
      "[404]\tvalid_0's l2: 0.106248\n",
      "[405]\tvalid_0's l2: 0.106255\n",
      "[406]\tvalid_0's l2: 0.10624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[407]\tvalid_0's l2: 0.106248\n",
      "[408]\tvalid_0's l2: 0.106247\n",
      "[409]\tvalid_0's l2: 0.106254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[410]\tvalid_0's l2: 0.106256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[411]\tvalid_0's l2: 0.10625\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[412]\tvalid_0's l2: 0.106254\n",
      "[413]\tvalid_0's l2: 0.106257\n",
      "[414]\tvalid_0's l2: 0.106258\n",
      "[415]\tvalid_0's l2: 0.106248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[416]\tvalid_0's l2: 0.106251\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[417]\tvalid_0's l2: 0.10625\n",
      "[418]\tvalid_0's l2: 0.106245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[419]\tvalid_0's l2: 0.106246\n",
      "[420]\tvalid_0's l2: 0.106241\n",
      "[421]\tvalid_0's l2: 0.106236\n",
      "[422]\tvalid_0's l2: 0.106251\n",
      "[423]\tvalid_0's l2: 0.106241\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[424]\tvalid_0's l2: 0.106236\n",
      "[425]\tvalid_0's l2: 0.106235\n",
      "[426]\tvalid_0's l2: 0.106227\n",
      "[427]\tvalid_0's l2: 0.106228\n",
      "[428]\tvalid_0's l2: 0.106241\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[429]\tvalid_0's l2: 0.106239\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[430]\tvalid_0's l2: 0.106223\n",
      "[431]\tvalid_0's l2: 0.106217\n",
      "[432]\tvalid_0's l2: 0.106214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[433]\tvalid_0's l2: 0.10621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[434]\tvalid_0's l2: 0.10621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[435]\tvalid_0's l2: 0.106207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[436]\tvalid_0's l2: 0.106212\n",
      "[437]\tvalid_0's l2: 0.106211\n",
      "[438]\tvalid_0's l2: 0.106202\n",
      "[439]\tvalid_0's l2: 0.106191\n",
      "[440]\tvalid_0's l2: 0.106188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[441]\tvalid_0's l2: 0.106195\n",
      "[442]\tvalid_0's l2: 0.106183\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[443]\tvalid_0's l2: 0.106191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[444]\tvalid_0's l2: 0.106186\n",
      "[445]\tvalid_0's l2: 0.106172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[446]\tvalid_0's l2: 0.106165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[447]\tvalid_0's l2: 0.106157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[448]\tvalid_0's l2: 0.106157\n",
      "[449]\tvalid_0's l2: 0.10617\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\tvalid_0's l2: 0.106178\n",
      "[451]\tvalid_0's l2: 0.106184\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[452]\tvalid_0's l2: 0.10619\n",
      "[453]\tvalid_0's l2: 0.106193\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[454]\tvalid_0's l2: 0.106201\n",
      "[455]\tvalid_0's l2: 0.106205\n",
      "[456]\tvalid_0's l2: 0.106195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[457]\tvalid_0's l2: 0.106191\n",
      "[458]\tvalid_0's l2: 0.106177\n",
      "[459]\tvalid_0's l2: 0.106174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[460]\tvalid_0's l2: 0.106175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[461]\tvalid_0's l2: 0.106171\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[462]\tvalid_0's l2: 0.106177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[463]\tvalid_0's l2: 0.106176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[464]\tvalid_0's l2: 0.106168\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[465]\tvalid_0's l2: 0.106159\n",
      "[466]\tvalid_0's l2: 0.106143\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[467]\tvalid_0's l2: 0.106157\n",
      "[468]\tvalid_0's l2: 0.106157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[469]\tvalid_0's l2: 0.106174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\tvalid_0's l2: 0.106173\n",
      "f1s: 0.09787234042553193\n",
      "Precision: 0.6764705882352942\n",
      "AUC: 0.7754601580982055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create a LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.72,\n",
    "    'learning_rate': 0.01642,\n",
    "    'max_depth': 23,\n",
    "    'min_child_samples': 60,\n",
    "    'num_leaves': 50,\n",
    "    'n_estimators': 470,\n",
    "    'scale_pos_weight': 8,\n",
    "    'subsample': 0.93446,\n",
    "    'reg_alpha': 0.30421732656825395\n",
    "\n",
    "}\n",
    "bst = lgb.train(best_params, train_data, valid_sets=[test_data])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bst.predict(X_test)\n",
    "# Convert to binary output\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "f1s = f1_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "auc = roc_auc_score(y_test, y_pred)  # y_pred is the probability, not the binary output\n",
    "\n",
    "print(f\"f1s: {f1s}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052752293577981654"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
