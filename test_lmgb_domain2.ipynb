{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "features_d2 = []\n",
    "labels_d2 = []\n",
    "# Open file for reading\n",
    "with open('domain2_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d2.append(obj['text'])\n",
    "        labels_d2.append(obj['label'])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_bow(sequences, dimension=5000):  # 5000 considering 0 to 4999\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for word_index in sequence:\n",
    "            results[i, word_index] += 1  # Increment by 1 for each occurrence\n",
    "    return results\n",
    "\n",
    "Bow_features = to_bow(features_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None)  \n",
    "\n",
    "# Fit and transform the data to text\n",
    "features_tfidf = tfidf.fit_transform(features_d2)\n",
    "label_d2 = np.array(labels_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      2544\n",
      "           1       0.28      0.29      0.29       436\n",
      "\n",
      "    accuracy                           0.79      2980\n",
      "   macro avg       0.58      0.58      0.58      2980\n",
      "weighted avg       0.79      0.79      0.79      2980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Bow_features, labels_d2, test_size=0.2, random_state=42)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Initialize and fit the model\n",
    "clf = SGDClassifier(loss=\"hinge\", class_weight={0: 1, 1: 6}, alpha=0.001, penalty='elasticnet')  # 'hinge' loss gives a linear SVM\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11761\n",
      "[LightGBM] [Info] Number of data points in the train set: 11920, number of used features: 2171\n",
      "[LightGBM] [Info] Start training from score 0.143792\n",
      "[1]\tvalid_0's l2: 0.124517\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l2: 0.12414\n",
      "[3]\tvalid_0's l2: 0.123725\n",
      "[4]\tvalid_0's l2: 0.123492\n",
      "[5]\tvalid_0's l2: 0.123176\n",
      "[6]\tvalid_0's l2: 0.122795\n",
      "[7]\tvalid_0's l2: 0.122434\n",
      "[8]\tvalid_0's l2: 0.122224\n",
      "[9]\tvalid_0's l2: 0.121909\n",
      "[10]\tvalid_0's l2: 0.121786\n",
      "[11]\tvalid_0's l2: 0.121468\n",
      "[12]\tvalid_0's l2: 0.121276\n",
      "[13]\tvalid_0's l2: 0.120968\n",
      "[14]\tvalid_0's l2: 0.120688\n",
      "[15]\tvalid_0's l2: 0.120409\n",
      "[16]\tvalid_0's l2: 0.120144\n",
      "[17]\tvalid_0's l2: 0.119933\n",
      "[18]\tvalid_0's l2: 0.119673\n",
      "[19]\tvalid_0's l2: 0.119403\n",
      "[20]\tvalid_0's l2: 0.119109\n",
      "[21]\tvalid_0's l2: 0.118964\n",
      "[22]\tvalid_0's l2: 0.118706\n",
      "[23]\tvalid_0's l2: 0.11856\n",
      "[24]\tvalid_0's l2: 0.118332\n",
      "[25]\tvalid_0's l2: 0.118058\n",
      "[26]\tvalid_0's l2: 0.117802\n",
      "[27]\tvalid_0's l2: 0.117533\n",
      "[28]\tvalid_0's l2: 0.117325\n",
      "[29]\tvalid_0's l2: 0.117098\n",
      "[30]\tvalid_0's l2: 0.116876\n",
      "[31]\tvalid_0's l2: 0.116666\n",
      "[32]\tvalid_0's l2: 0.116548\n",
      "[33]\tvalid_0's l2: 0.116379\n",
      "[34]\tvalid_0's l2: 0.116257\n",
      "[35]\tvalid_0's l2: 0.116073\n",
      "[36]\tvalid_0's l2: 0.115943\n",
      "[37]\tvalid_0's l2: 0.115757\n",
      "[38]\tvalid_0's l2: 0.115536\n",
      "[39]\tvalid_0's l2: 0.115356\n",
      "[40]\tvalid_0's l2: 0.115179\n",
      "[41]\tvalid_0's l2: 0.11512\n",
      "[42]\tvalid_0's l2: 0.114944\n",
      "[43]\tvalid_0's l2: 0.114807\n",
      "[44]\tvalid_0's l2: 0.114733\n",
      "[45]\tvalid_0's l2: 0.114575\n",
      "[46]\tvalid_0's l2: 0.114425\n",
      "[47]\tvalid_0's l2: 0.11432\n",
      "[48]\tvalid_0's l2: 0.114134\n",
      "[49]\tvalid_0's l2: 0.11407\n",
      "[50]\tvalid_0's l2: 0.113901\n",
      "[51]\tvalid_0's l2: 0.113778\n",
      "[52]\tvalid_0's l2: 0.113688\n",
      "[53]\tvalid_0's l2: 0.11352\n",
      "[54]\tvalid_0's l2: 0.113442\n",
      "[55]\tvalid_0's l2: 0.113318\n",
      "[56]\tvalid_0's l2: 0.113172\n",
      "[57]\tvalid_0's l2: 0.113044\n",
      "[58]\tvalid_0's l2: 0.112985\n",
      "[59]\tvalid_0's l2: 0.112951\n",
      "[60]\tvalid_0's l2: 0.112825\n",
      "[61]\tvalid_0's l2: 0.112727\n",
      "[62]\tvalid_0's l2: 0.112612\n",
      "[63]\tvalid_0's l2: 0.112592\n",
      "[64]\tvalid_0's l2: 0.112469\n",
      "[65]\tvalid_0's l2: 0.112339\n",
      "[66]\tvalid_0's l2: 0.112248\n",
      "[67]\tvalid_0's l2: 0.112173\n",
      "[68]\tvalid_0's l2: 0.112056\n",
      "[69]\tvalid_0's l2: 0.112023\n",
      "[70]\tvalid_0's l2: 0.111929\n",
      "[71]\tvalid_0's l2: 0.111825\n",
      "[72]\tvalid_0's l2: 0.111755\n",
      "[73]\tvalid_0's l2: 0.111648\n",
      "[74]\tvalid_0's l2: 0.11155\n",
      "[75]\tvalid_0's l2: 0.111519\n",
      "[76]\tvalid_0's l2: 0.111435\n",
      "[77]\tvalid_0's l2: 0.111327\n",
      "[78]\tvalid_0's l2: 0.111232\n",
      "[79]\tvalid_0's l2: 0.111131\n",
      "[80]\tvalid_0's l2: 0.111082\n",
      "[81]\tvalid_0's l2: 0.111009\n",
      "[82]\tvalid_0's l2: 0.110932\n",
      "[83]\tvalid_0's l2: 0.110822\n",
      "[84]\tvalid_0's l2: 0.110735\n",
      "[85]\tvalid_0's l2: 0.110657\n",
      "[86]\tvalid_0's l2: 0.110657\n",
      "[87]\tvalid_0's l2: 0.110582\n",
      "[88]\tvalid_0's l2: 0.110568\n",
      "[89]\tvalid_0's l2: 0.110519\n",
      "[90]\tvalid_0's l2: 0.110463\n",
      "[91]\tvalid_0's l2: 0.110436\n",
      "[92]\tvalid_0's l2: 0.110392\n",
      "[93]\tvalid_0's l2: 0.110334\n",
      "[94]\tvalid_0's l2: 0.110277\n",
      "[95]\tvalid_0's l2: 0.110205\n",
      "[96]\tvalid_0's l2: 0.110145\n",
      "[97]\tvalid_0's l2: 0.110105\n",
      "[98]\tvalid_0's l2: 0.110081\n",
      "[99]\tvalid_0's l2: 0.11002\n",
      "[100]\tvalid_0's l2: 0.109945\n",
      "[101]\tvalid_0's l2: 0.109893\n",
      "[102]\tvalid_0's l2: 0.10984\n",
      "[103]\tvalid_0's l2: 0.109789\n",
      "[104]\tvalid_0's l2: 0.109715\n",
      "[105]\tvalid_0's l2: 0.109655\n",
      "[106]\tvalid_0's l2: 0.109607\n",
      "[107]\tvalid_0's l2: 0.109531\n",
      "[108]\tvalid_0's l2: 0.109461\n",
      "[109]\tvalid_0's l2: 0.109415\n",
      "[110]\tvalid_0's l2: 0.109377\n",
      "[111]\tvalid_0's l2: 0.109323\n",
      "[112]\tvalid_0's l2: 0.109226\n",
      "[113]\tvalid_0's l2: 0.109172\n",
      "[114]\tvalid_0's l2: 0.10911\n",
      "[115]\tvalid_0's l2: 0.10905\n",
      "[116]\tvalid_0's l2: 0.108997\n",
      "[117]\tvalid_0's l2: 0.108942\n",
      "[118]\tvalid_0's l2: 0.108923\n",
      "[119]\tvalid_0's l2: 0.108897\n",
      "[120]\tvalid_0's l2: 0.108877\n",
      "[121]\tvalid_0's l2: 0.108813\n",
      "[122]\tvalid_0's l2: 0.108777\n",
      "[123]\tvalid_0's l2: 0.108753\n",
      "[124]\tvalid_0's l2: 0.108756\n",
      "[125]\tvalid_0's l2: 0.108725\n",
      "[126]\tvalid_0's l2: 0.108665\n",
      "[127]\tvalid_0's l2: 0.108656\n",
      "[128]\tvalid_0's l2: 0.108602\n",
      "[129]\tvalid_0's l2: 0.108567\n",
      "[130]\tvalid_0's l2: 0.108508\n",
      "[131]\tvalid_0's l2: 0.108435\n",
      "[132]\tvalid_0's l2: 0.108437\n",
      "[133]\tvalid_0's l2: 0.108395\n",
      "[134]\tvalid_0's l2: 0.108348\n",
      "[135]\tvalid_0's l2: 0.108358\n",
      "[136]\tvalid_0's l2: 0.108315\n",
      "[137]\tvalid_0's l2: 0.108286\n",
      "[138]\tvalid_0's l2: 0.108269\n",
      "[139]\tvalid_0's l2: 0.108229\n",
      "[140]\tvalid_0's l2: 0.108209\n",
      "[141]\tvalid_0's l2: 0.108204\n",
      "[142]\tvalid_0's l2: 0.108165\n",
      "[143]\tvalid_0's l2: 0.108094\n",
      "[144]\tvalid_0's l2: 0.108057\n",
      "[145]\tvalid_0's l2: 0.108034\n",
      "[146]\tvalid_0's l2: 0.108045\n",
      "[147]\tvalid_0's l2: 0.108034\n",
      "[148]\tvalid_0's l2: 0.108013\n",
      "[149]\tvalid_0's l2: 0.107992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's l2: 0.107972\n",
      "[151]\tvalid_0's l2: 0.10795\n",
      "[152]\tvalid_0's l2: 0.107933\n",
      "[153]\tvalid_0's l2: 0.10788\n",
      "[154]\tvalid_0's l2: 0.107876\n",
      "[155]\tvalid_0's l2: 0.107847\n",
      "[156]\tvalid_0's l2: 0.107841\n",
      "[157]\tvalid_0's l2: 0.107814\n",
      "[158]\tvalid_0's l2: 0.107788\n",
      "[159]\tvalid_0's l2: 0.107761\n",
      "[160]\tvalid_0's l2: 0.107731\n",
      "[161]\tvalid_0's l2: 0.107713\n",
      "[162]\tvalid_0's l2: 0.107692\n",
      "[163]\tvalid_0's l2: 0.107662\n",
      "[164]\tvalid_0's l2: 0.107633\n",
      "[165]\tvalid_0's l2: 0.107605\n",
      "[166]\tvalid_0's l2: 0.107611\n",
      "[167]\tvalid_0's l2: 0.107599\n",
      "[168]\tvalid_0's l2: 0.107597\n",
      "[169]\tvalid_0's l2: 0.107594\n",
      "[170]\tvalid_0's l2: 0.10756\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[171]\tvalid_0's l2: 0.107561\n",
      "[172]\tvalid_0's l2: 0.107529\n",
      "[173]\tvalid_0's l2: 0.107509\n",
      "[174]\tvalid_0's l2: 0.10749\n",
      "[175]\tvalid_0's l2: 0.107472\n",
      "[176]\tvalid_0's l2: 0.107472\n",
      "[177]\tvalid_0's l2: 0.107435\n",
      "[178]\tvalid_0's l2: 0.107431\n",
      "[179]\tvalid_0's l2: 0.107419\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\tvalid_0's l2: 0.107417\n",
      "[181]\tvalid_0's l2: 0.1074\n",
      "[182]\tvalid_0's l2: 0.10737\n",
      "[183]\tvalid_0's l2: 0.107359\n",
      "[184]\tvalid_0's l2: 0.107331\n",
      "[185]\tvalid_0's l2: 0.107305\n",
      "[186]\tvalid_0's l2: 0.107303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[187]\tvalid_0's l2: 0.107288\n",
      "[188]\tvalid_0's l2: 0.107267\n",
      "[189]\tvalid_0's l2: 0.107254\n",
      "[190]\tvalid_0's l2: 0.107249\n",
      "[191]\tvalid_0's l2: 0.107222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[192]\tvalid_0's l2: 0.107225\n",
      "[193]\tvalid_0's l2: 0.107192\n",
      "[194]\tvalid_0's l2: 0.107201\n",
      "[195]\tvalid_0's l2: 0.107181\n",
      "[196]\tvalid_0's l2: 0.107176\n",
      "[197]\tvalid_0's l2: 0.107169\n",
      "[198]\tvalid_0's l2: 0.10715\n",
      "[199]\tvalid_0's l2: 0.107145\n",
      "[200]\tvalid_0's l2: 0.107135\n",
      "[201]\tvalid_0's l2: 0.107126\n",
      "[202]\tvalid_0's l2: 0.107112\n",
      "[203]\tvalid_0's l2: 0.107094\n",
      "[204]\tvalid_0's l2: 0.107069\n",
      "[205]\tvalid_0's l2: 0.107053\n",
      "[206]\tvalid_0's l2: 0.107032\n",
      "[207]\tvalid_0's l2: 0.107019\n",
      "[208]\tvalid_0's l2: 0.107004\n",
      "[209]\tvalid_0's l2: 0.107012\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\tvalid_0's l2: 0.107003\n",
      "[211]\tvalid_0's l2: 0.106983\n",
      "[212]\tvalid_0's l2: 0.106973\n",
      "[213]\tvalid_0's l2: 0.106956\n",
      "[214]\tvalid_0's l2: 0.106969\n",
      "[215]\tvalid_0's l2: 0.106976\n",
      "[216]\tvalid_0's l2: 0.106972\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[217]\tvalid_0's l2: 0.10698\n",
      "[218]\tvalid_0's l2: 0.106971\n",
      "[219]\tvalid_0's l2: 0.106972\n",
      "[220]\tvalid_0's l2: 0.106964\n",
      "[221]\tvalid_0's l2: 0.106963\n",
      "[222]\tvalid_0's l2: 0.106976\n",
      "[223]\tvalid_0's l2: 0.106998\n",
      "[224]\tvalid_0's l2: 0.106976\n",
      "[225]\tvalid_0's l2: 0.106968\n",
      "[226]\tvalid_0's l2: 0.106947\n",
      "[227]\tvalid_0's l2: 0.106953\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[228]\tvalid_0's l2: 0.106961\n",
      "[229]\tvalid_0's l2: 0.106957\n",
      "[230]\tvalid_0's l2: 0.106956\n",
      "[231]\tvalid_0's l2: 0.106948\n",
      "[232]\tvalid_0's l2: 0.106942\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[233]\tvalid_0's l2: 0.106948\n",
      "[234]\tvalid_0's l2: 0.106944\n",
      "[235]\tvalid_0's l2: 0.106941\n",
      "[236]\tvalid_0's l2: 0.106942\n",
      "[237]\tvalid_0's l2: 0.106926\n",
      "[238]\tvalid_0's l2: 0.106935\n",
      "[239]\tvalid_0's l2: 0.106926\n",
      "[240]\tvalid_0's l2: 0.106917\n",
      "[241]\tvalid_0's l2: 0.106899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[242]\tvalid_0's l2: 0.106897\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[243]\tvalid_0's l2: 0.106881\n",
      "[244]\tvalid_0's l2: 0.106874\n",
      "[245]\tvalid_0's l2: 0.10688\n",
      "[246]\tvalid_0's l2: 0.106877\n",
      "[247]\tvalid_0's l2: 0.106879\n",
      "[248]\tvalid_0's l2: 0.106869\n",
      "[249]\tvalid_0's l2: 0.106861\n",
      "[250]\tvalid_0's l2: 0.106861\n",
      "[251]\tvalid_0's l2: 0.106868\n",
      "[252]\tvalid_0's l2: 0.106866\n",
      "[253]\tvalid_0's l2: 0.106877\n",
      "[254]\tvalid_0's l2: 0.106862\n",
      "[255]\tvalid_0's l2: 0.106846\n",
      "[256]\tvalid_0's l2: 0.106842\n",
      "[257]\tvalid_0's l2: 0.106809\n",
      "[258]\tvalid_0's l2: 0.106812\n",
      "[259]\tvalid_0's l2: 0.106802\n",
      "[260]\tvalid_0's l2: 0.1068\n",
      "[261]\tvalid_0's l2: 0.106783\n",
      "[262]\tvalid_0's l2: 0.106773\n",
      "[263]\tvalid_0's l2: 0.106768\n",
      "[264]\tvalid_0's l2: 0.106759\n",
      "[265]\tvalid_0's l2: 0.106753\n",
      "[266]\tvalid_0's l2: 0.106752\n",
      "[267]\tvalid_0's l2: 0.10675\n",
      "[268]\tvalid_0's l2: 0.106758\n",
      "[269]\tvalid_0's l2: 0.10674\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[270]\tvalid_0's l2: 0.106733\n",
      "[271]\tvalid_0's l2: 0.10672\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[272]\tvalid_0's l2: 0.106723\n",
      "[273]\tvalid_0's l2: 0.106731\n",
      "[274]\tvalid_0's l2: 0.106727\n",
      "[275]\tvalid_0's l2: 0.106711\n",
      "[276]\tvalid_0's l2: 0.106707\n",
      "[277]\tvalid_0's l2: 0.106697\n",
      "[278]\tvalid_0's l2: 0.106686\n",
      "[279]\tvalid_0's l2: 0.106685\n",
      "[280]\tvalid_0's l2: 0.106687\n",
      "[281]\tvalid_0's l2: 0.106673\n",
      "[282]\tvalid_0's l2: 0.106668\n",
      "[283]\tvalid_0's l2: 0.106667\n",
      "[284]\tvalid_0's l2: 0.106643\n",
      "[285]\tvalid_0's l2: 0.106626\n",
      "[286]\tvalid_0's l2: 0.106632\n",
      "[287]\tvalid_0's l2: 0.106628\n",
      "[288]\tvalid_0's l2: 0.106643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[289]\tvalid_0's l2: 0.10665\n",
      "[290]\tvalid_0's l2: 0.10665\n",
      "[291]\tvalid_0's l2: 0.106638\n",
      "[292]\tvalid_0's l2: 0.106655\n",
      "[293]\tvalid_0's l2: 0.106654\n",
      "[294]\tvalid_0's l2: 0.106644\n",
      "[295]\tvalid_0's l2: 0.106626\n",
      "[296]\tvalid_0's l2: 0.106612\n",
      "[297]\tvalid_0's l2: 0.106617\n",
      "[298]\tvalid_0's l2: 0.106604\n",
      "[299]\tvalid_0's l2: 0.106595\n",
      "[300]\tvalid_0's l2: 0.106585\n",
      "[301]\tvalid_0's l2: 0.106576\n",
      "[302]\tvalid_0's l2: 0.106581\n",
      "[303]\tvalid_0's l2: 0.106593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[304]\tvalid_0's l2: 0.106613\n",
      "[305]\tvalid_0's l2: 0.106605\n",
      "[306]\tvalid_0's l2: 0.106594\n",
      "[307]\tvalid_0's l2: 0.10659\n",
      "[308]\tvalid_0's l2: 0.106579\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[309]\tvalid_0's l2: 0.106579\n",
      "[310]\tvalid_0's l2: 0.106567\n",
      "[311]\tvalid_0's l2: 0.106545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[312]\tvalid_0's l2: 0.106555\n",
      "[313]\tvalid_0's l2: 0.106538\n",
      "[314]\tvalid_0's l2: 0.106543\n",
      "[315]\tvalid_0's l2: 0.106543\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[316]\tvalid_0's l2: 0.106537\n",
      "[317]\tvalid_0's l2: 0.106532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[318]\tvalid_0's l2: 0.106525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[319]\tvalid_0's l2: 0.106518\n",
      "[320]\tvalid_0's l2: 0.106506\n",
      "[321]\tvalid_0's l2: 0.106492\n",
      "[322]\tvalid_0's l2: 0.106486\n",
      "[323]\tvalid_0's l2: 0.106495\n",
      "[324]\tvalid_0's l2: 0.106481\n",
      "[325]\tvalid_0's l2: 0.106488\n",
      "[326]\tvalid_0's l2: 0.106494\n",
      "[327]\tvalid_0's l2: 0.106476\n",
      "[328]\tvalid_0's l2: 0.106501\n",
      "[329]\tvalid_0's l2: 0.106508\n",
      "[330]\tvalid_0's l2: 0.106505\n",
      "[331]\tvalid_0's l2: 0.1065\n",
      "[332]\tvalid_0's l2: 0.1065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[333]\tvalid_0's l2: 0.106482\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[334]\tvalid_0's l2: 0.106478\n",
      "[335]\tvalid_0's l2: 0.106483\n",
      "[336]\tvalid_0's l2: 0.106457\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[337]\tvalid_0's l2: 0.10646\n",
      "[338]\tvalid_0's l2: 0.106452\n",
      "[339]\tvalid_0's l2: 0.106455\n",
      "[340]\tvalid_0's l2: 0.10646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[341]\tvalid_0's l2: 0.106454\n",
      "[342]\tvalid_0's l2: 0.106443\n",
      "[343]\tvalid_0's l2: 0.106424\n",
      "[344]\tvalid_0's l2: 0.106437\n",
      "[345]\tvalid_0's l2: 0.106443\n",
      "[346]\tvalid_0's l2: 0.106437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[347]\tvalid_0's l2: 0.106438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[348]\tvalid_0's l2: 0.10644\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[349]\tvalid_0's l2: 0.106431\n",
      "[350]\tvalid_0's l2: 0.106428\n",
      "[351]\tvalid_0's l2: 0.106416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[352]\tvalid_0's l2: 0.106402\n",
      "[353]\tvalid_0's l2: 0.106409\n",
      "[354]\tvalid_0's l2: 0.106394\n",
      "[355]\tvalid_0's l2: 0.106397\n",
      "[356]\tvalid_0's l2: 0.10641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[357]\tvalid_0's l2: 0.106417\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[358]\tvalid_0's l2: 0.10643\n",
      "[359]\tvalid_0's l2: 0.106411\n",
      "[360]\tvalid_0's l2: 0.106403\n",
      "[361]\tvalid_0's l2: 0.106383\n",
      "[362]\tvalid_0's l2: 0.106367\n",
      "[363]\tvalid_0's l2: 0.106359\n",
      "[364]\tvalid_0's l2: 0.106342\n",
      "[365]\tvalid_0's l2: 0.106344\n",
      "[366]\tvalid_0's l2: 0.106337\n",
      "[367]\tvalid_0's l2: 0.106328\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[368]\tvalid_0's l2: 0.106326\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[369]\tvalid_0's l2: 0.106336\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[370]\tvalid_0's l2: 0.106322\n",
      "[371]\tvalid_0's l2: 0.106337\n",
      "[372]\tvalid_0's l2: 0.106332\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[373]\tvalid_0's l2: 0.106342\n",
      "[374]\tvalid_0's l2: 0.106333\n",
      "[375]\tvalid_0's l2: 0.10633\n",
      "[376]\tvalid_0's l2: 0.106322\n",
      "[377]\tvalid_0's l2: 0.106319\n",
      "[378]\tvalid_0's l2: 0.106306\n",
      "[379]\tvalid_0's l2: 0.106294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\tvalid_0's l2: 0.106302\n",
      "[381]\tvalid_0's l2: 0.106309\n",
      "[382]\tvalid_0's l2: 0.106302\n",
      "[383]\tvalid_0's l2: 0.106303\n",
      "[384]\tvalid_0's l2: 0.106296\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[385]\tvalid_0's l2: 0.1063\n",
      "[386]\tvalid_0's l2: 0.106298\n",
      "[387]\tvalid_0's l2: 0.106309\n",
      "[388]\tvalid_0's l2: 0.106304\n",
      "[389]\tvalid_0's l2: 0.106293\n",
      "[390]\tvalid_0's l2: 0.106301\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[391]\tvalid_0's l2: 0.106299\n",
      "[392]\tvalid_0's l2: 0.106308\n",
      "[393]\tvalid_0's l2: 0.106296\n",
      "[394]\tvalid_0's l2: 0.106302\n",
      "[395]\tvalid_0's l2: 0.106306\n",
      "[396]\tvalid_0's l2: 0.106314\n",
      "[397]\tvalid_0's l2: 0.106322\n",
      "[398]\tvalid_0's l2: 0.106325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[399]\tvalid_0's l2: 0.106334\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's l2: 0.106334\n",
      "[401]\tvalid_0's l2: 0.106332\n",
      "[402]\tvalid_0's l2: 0.106327\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[403]\tvalid_0's l2: 0.106329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[404]\tvalid_0's l2: 0.10632\n",
      "[405]\tvalid_0's l2: 0.106318\n",
      "[406]\tvalid_0's l2: 0.106319\n",
      "[407]\tvalid_0's l2: 0.10631\n",
      "[408]\tvalid_0's l2: 0.106307\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[409]\tvalid_0's l2: 0.106311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[410]\tvalid_0's l2: 0.106319\n",
      "[411]\tvalid_0's l2: 0.106332\n",
      "[412]\tvalid_0's l2: 0.106342\n",
      "[413]\tvalid_0's l2: 0.106352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[414]\tvalid_0's l2: 0.106354\n",
      "[415]\tvalid_0's l2: 0.106348\n",
      "[416]\tvalid_0's l2: 0.106335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[417]\tvalid_0's l2: 0.10633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[418]\tvalid_0's l2: 0.106327\n",
      "[419]\tvalid_0's l2: 0.106311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[420]\tvalid_0's l2: 0.106312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[421]\tvalid_0's l2: 0.106293\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[422]\tvalid_0's l2: 0.106282\n",
      "[423]\tvalid_0's l2: 0.106284\n",
      "[424]\tvalid_0's l2: 0.106288\n",
      "[425]\tvalid_0's l2: 0.10628\n",
      "[426]\tvalid_0's l2: 0.106289\n",
      "[427]\tvalid_0's l2: 0.106293\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[428]\tvalid_0's l2: 0.106299\n",
      "[429]\tvalid_0's l2: 0.106294\n",
      "[430]\tvalid_0's l2: 0.106289\n",
      "[431]\tvalid_0's l2: 0.10629\n",
      "[432]\tvalid_0's l2: 0.106281\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[433]\tvalid_0's l2: 0.10628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[434]\tvalid_0's l2: 0.106288\n",
      "[435]\tvalid_0's l2: 0.106276\n",
      "[436]\tvalid_0's l2: 0.106276\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[437]\tvalid_0's l2: 0.106271\n",
      "[438]\tvalid_0's l2: 0.106266\n",
      "[439]\tvalid_0's l2: 0.106261\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[440]\tvalid_0's l2: 0.106258\n",
      "[441]\tvalid_0's l2: 0.106252\n",
      "[442]\tvalid_0's l2: 0.106254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[443]\tvalid_0's l2: 0.106251\n",
      "[444]\tvalid_0's l2: 0.106248\n",
      "[445]\tvalid_0's l2: 0.106259\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[446]\tvalid_0's l2: 0.106258\n",
      "[447]\tvalid_0's l2: 0.106249\n",
      "[448]\tvalid_0's l2: 0.106237\n",
      "[449]\tvalid_0's l2: 0.106236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\tvalid_0's l2: 0.106247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[451]\tvalid_0's l2: 0.106236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[452]\tvalid_0's l2: 0.106234\n",
      "[453]\tvalid_0's l2: 0.106234\n",
      "[454]\tvalid_0's l2: 0.106219\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[455]\tvalid_0's l2: 0.106228\n",
      "[456]\tvalid_0's l2: 0.106217\n",
      "[457]\tvalid_0's l2: 0.106226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[458]\tvalid_0's l2: 0.106221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[459]\tvalid_0's l2: 0.106224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[460]\tvalid_0's l2: 0.106236\n",
      "[461]\tvalid_0's l2: 0.106245\n",
      "[462]\tvalid_0's l2: 0.106233\n",
      "[463]\tvalid_0's l2: 0.106242\n",
      "[464]\tvalid_0's l2: 0.106248\n",
      "[465]\tvalid_0's l2: 0.106249\n",
      "[466]\tvalid_0's l2: 0.106242\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[467]\tvalid_0's l2: 0.106238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[468]\tvalid_0's l2: 0.106247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[469]\tvalid_0's l2: 0.106247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\tvalid_0's l2: 0.106252\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[456]\tvalid_0's l2: 0.106217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Bow_features, labels_d2, test_size=0.2, random_state=42)\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label=y_train)  \n",
    "d_test = lgb.Dataset(X_test, label=y_test)  \n",
    "\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.72,\n",
    "    'learning_rate': 0.01642,\n",
    "    'max_depth': 23,\n",
    "    'min_child_samples': 60,\n",
    "    'num_leaves': 50,\n",
    "    'n_estimators': 470,\n",
    "    'scale_pos_weight': 8,\n",
    "    'subsample': 0.93446,\n",
    "    'reg_alpha': 0.30421732656825395\n",
    "\n",
    "}\n",
    "\n",
    "clf = lgb.train(best_params, d_train,verbose_eval=1, num_boost_round=25000,  valid_sets=[d_test], early_stopping_rounds=1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predicted classes\n",
    "y_val_pred_class = [1 if x >= 0.5 else 0 for x in clf.predict(X_test)]\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_val_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      2544\n",
      "           1       0.63      0.10      0.17       436\n",
      "\n",
      "    accuracy                           0.86      2980\n",
      "   macro avg       0.75      0.54      0.55      2980\n",
      "weighted avg       0.83      0.86      0.81      2980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None)  \n",
    "\n",
    "# Fit and transform the data to text\n",
    "features_tfidf = tfidf.fit_transform(features_d2)\n",
    "label_d2 = np.array(labels_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the trained vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tfidf, labels_d2, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679;, score=0.421 total time=   3.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679;, score=0.369 total time=   3.9s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679;, score=0.416 total time=   3.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679;, score=0.375 total time=   3.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.783842418575133, learning_rate=0.014772439883158385, max_depth=80, min_child_samples=148, n_estimators=685, num_leaves=109, reg_alpha=0.008502122718325624, scale_pos_weight=10, subsample=0.7511734711732679;, score=0.439 total time=   4.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444;, score=0.423 total time=   5.1s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444;, score=0.361 total time=   5.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444;, score=0.413 total time=   5.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444;, score=0.370 total time=   5.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.7349797690447063, learning_rate=0.016821796426642045, max_depth=90, min_child_samples=153, n_estimators=1046, num_leaves=101, reg_alpha=0.6415244813603014, scale_pos_weight=7, subsample=0.7972276208280444;, score=0.459 total time=   5.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507;, score=0.434 total time=   4.7s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507;, score=0.367 total time=   4.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507;, score=0.426 total time=   4.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507;, score=0.385 total time=   5.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.961623760976219, learning_rate=0.010617657211782849, max_depth=97, min_child_samples=151, n_estimators=689, num_leaves=115, reg_alpha=0.9010072232378737, scale_pos_weight=6, subsample=0.8950285683812507;, score=0.442 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522;, score=0.397 total time=   5.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522;, score=0.349 total time=   5.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522;, score=0.371 total time=   5.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522;, score=0.340 total time=   5.4s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6464823076031248, learning_rate=0.03202143594389269, max_depth=97, min_child_samples=155, n_estimators=1176, num_leaves=104, reg_alpha=0.16216475014611012, scale_pos_weight=8, subsample=0.9485684748628522;, score=0.422 total time=   5.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068;, score=0.403 total time=   4.7s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068;, score=0.356 total time=   4.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068;, score=0.386 total time=   4.7s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068;, score=0.350 total time=   4.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9665500640180035, learning_rate=0.03640771667542423, max_depth=87, min_child_samples=149, n_estimators=1030, num_leaves=112, reg_alpha=0.9787788592815853, scale_pos_weight=9, subsample=0.95500963730068;, score=0.418 total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153;, score=0.387 total time=   3.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153;, score=0.320 total time=   4.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153;, score=0.343 total time=   4.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153;, score=0.337 total time=   4.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6647940552967678, learning_rate=0.07594857071782452, max_depth=108, min_child_samples=146, n_estimators=917, num_leaves=111, reg_alpha=0.4263978394371192, scale_pos_weight=9, subsample=0.728044347213153;, score=0.379 total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292;, score=0.417 total time=   3.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292;, score=0.369 total time=   3.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292;, score=0.413 total time=   3.6s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292;, score=0.376 total time=   3.4s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6301346628052386, learning_rate=0.01037922638431511, max_depth=84, min_child_samples=156, n_estimators=679, num_leaves=118, reg_alpha=0.09550698317693221, scale_pos_weight=8, subsample=0.9414499370032292;, score=0.439 total time=   3.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144;, score=0.411 total time=   4.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144;, score=0.360 total time=   4.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144;, score=0.398 total time=   4.6s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144;, score=0.363 total time=   4.7s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6630892909054508, learning_rate=0.029689508990012273, max_depth=83, min_child_samples=160, n_estimators=1155, num_leaves=110, reg_alpha=0.6737419580683237, scale_pos_weight=9, subsample=0.8154866357255144;, score=0.438 total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913;, score=0.427 total time=   4.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913;, score=0.374 total time=   4.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913;, score=0.421 total time=   4.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913;, score=0.386 total time=   4.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8925435203016032, learning_rate=0.01248863612957428, max_depth=106, min_child_samples=152, n_estimators=877, num_leaves=106, reg_alpha=0.32873478374416837, scale_pos_weight=8, subsample=0.8263135632739913;, score=0.446 total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656;, score=0.376 total time=   2.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656;, score=0.322 total time=   2.8s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656;, score=0.342 total time=   2.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656;, score=0.353 total time=   2.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6639851570140763, learning_rate=0.08434688200817242, max_depth=102, min_child_samples=156, n_estimators=611, num_leaves=120, reg_alpha=0.04058208923298879, scale_pos_weight=6, subsample=0.7270924582005656;, score=0.368 total time=   2.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.423 total time=   7.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.351 total time=   8.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.405 total time=   8.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.358 total time=   7.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.454 total time=   7.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214;, score=0.419 total time=   4.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214;, score=0.371 total time=   4.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214;, score=0.408 total time=   4.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214;, score=0.386 total time=   5.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=1069, num_leaves=120, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8321527029196214;, score=0.433 total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0;, score=0.418 total time=   6.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0;, score=0.378 total time=   5.9s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0;, score=0.413 total time=   7.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0;, score=0.390 total time=   7.0s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=0.0, scale_pos_weight=10, subsample=1.0;, score=0.446 total time=   6.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098;, score=0.419 total time=   6.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098;, score=0.359 total time=   6.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098;, score=0.397 total time=   7.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098;, score=0.357 total time=   7.7s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9840220597819902, learning_rate=0.01772462812887122, max_depth=110, min_child_samples=143, n_estimators=1114, num_leaves=109, reg_alpha=0.4743673178870662, scale_pos_weight=6, subsample=0.9785453573755098;, score=0.442 total time=   8.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376;, score=0.415 total time=   4.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376;, score=0.376 total time=   4.4s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376;, score=0.412 total time=   4.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376;, score=0.386 total time=   3.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=98, min_child_samples=143, n_estimators=651, num_leaves=100, reg_alpha=0.5102285374771202, scale_pos_weight=9, subsample=0.9715618632989376;, score=0.430 total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851;, score=0.433 total time=   4.8s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851;, score=0.360 total time=   4.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851;, score=0.412 total time=   5.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851;, score=0.360 total time=   4.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01246872109467139, max_depth=99, min_child_samples=160, n_estimators=805, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=0.8531361010433851;, score=0.444 total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635;, score=0.422 total time=   5.3s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635;, score=0.378 total time=   5.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635;, score=0.430 total time=   5.5s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635;, score=0.386 total time=   4.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6915100711795957, learning_rate=0.010355565762216848, max_depth=80, min_child_samples=143, n_estimators=901, num_leaves=100, reg_alpha=0.947914181540724, scale_pos_weight=7, subsample=0.7806775665122635;, score=0.440 total time=   5.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7;, score=0.422 total time=   3.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7;, score=0.365 total time=   3.5s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7;, score=0.422 total time=   3.3s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7;, score=0.373 total time=   3.6s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=0.0, scale_pos_weight=5, subsample=0.7;, score=0.451 total time=   3.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7;, score=0.422 total time=   7.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7;, score=0.347 total time=   7.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7;, score=0.415 total time=   7.8s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7;, score=0.366 total time=   8.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6, learning_rate=0.01, max_depth=95, min_child_samples=160, n_estimators=1200, num_leaves=109, reg_alpha=0.2966719946241517, scale_pos_weight=5, subsample=0.7;, score=0.451 total time=  10.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.429 total time=   3.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.361 total time=   5.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.423 total time=   4.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.373 total time=   5.9s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8095628103835704, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=120, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.437 total time=   5.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616;, score=0.325 total time=  10.2s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616;, score=0.294 total time=  10.0s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616;, score=0.318 total time=  10.8s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616;, score=0.309 total time=  11.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.8369792069054084, learning_rate=0.1, max_depth=80, min_child_samples=140, n_estimators=770, num_leaves=102, reg_alpha=0.0012156162113772905, scale_pos_weight=8, subsample=0.7729058811049616;, score=0.375 total time=   9.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514;, score=0.400 total time=   6.5s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514;, score=0.373 total time=   6.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514;, score=0.390 total time=   6.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514;, score=0.387 total time=   6.4s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=101, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8568666954220514;, score=0.413 total time=   7.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7;, score=0.421 total time=  15.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7;, score=0.375 total time=  13.8s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7;, score=0.420 total time=  13.2s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7;, score=0.382 total time=  13.8s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.9498970463476055, learning_rate=0.013803263959155185, max_depth=103, min_child_samples=155, n_estimators=1200, num_leaves=100, reg_alpha=0.12042413912707138, scale_pos_weight=9, subsample=0.7;, score=0.444 total time=  12.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509;, score=0.425 total time=  17.9s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509;, score=0.356 total time=  14.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509;, score=0.406 total time=  16.2s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509;, score=0.355 total time=  16.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6, learning_rate=0.02223746309681761, max_depth=110, min_child_samples=140, n_estimators=1200, num_leaves=103, reg_alpha=1.0, scale_pos_weight=10, subsample=0.8535718242288509;, score=0.436 total time=  15.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.433 total time=   5.8s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.363 total time=   5.6s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.419 total time=   5.4s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.378 total time=   5.3s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=0.7;, score=0.446 total time=   5.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7;, score=0.427 total time=   6.6s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7;, score=0.381 total time=   8.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7;, score=0.422 total time=   5.9s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7;, score=0.377 total time=   6.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.022290624814618763, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=120, reg_alpha=0.8341352171807901, scale_pos_weight=9, subsample=0.7;, score=0.439 total time=   7.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.428 total time=   7.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.373 total time=   6.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.403 total time=   6.2s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.373 total time=   6.1s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=140, n_estimators=600, num_leaves=100, reg_alpha=1.0, scale_pos_weight=5, subsample=1.0;, score=0.444 total time=   5.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0;, score=0.413 total time=   6.4s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0;, score=0.376 total time=   6.2s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0;, score=0.410 total time=   7.0s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0;, score=0.379 total time=   6.7s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.01, max_depth=110, min_child_samples=160, n_estimators=1200, num_leaves=100, reg_alpha=1.0, scale_pos_weight=8, subsample=1.0;, score=0.439 total time=   6.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7;, score=0.423 total time=   4.0s\n",
      "[CV 2/5; 1/1] START colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7;, score=0.371 total time=   4.3s\n",
      "[CV 3/5; 1/1] START colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7;, score=0.412 total time=   3.6s\n",
      "[CV 4/5; 1/1] START colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7;, score=0.380 total time=   3.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=1.0, learning_rate=0.014432016305684118, max_depth=80, min_child_samples=160, n_estimators=600, num_leaves=102, reg_alpha=1.0, scale_pos_weight=7, subsample=0.7;, score=0.439 total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7\n",
      "[CV 1/5; 1/1] END colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7;, score=0.408 total time=   4.5s\n",
      "[CV 2/5; 1/1] START colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7\n",
      "[CV 2/5; 1/1] END colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7;, score=0.378 total time=   4.7s\n",
      "[CV 3/5; 1/1] START colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7\n",
      "[CV 3/5; 1/1] END colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7;, score=0.411 total time=   4.7s\n",
      "[CV 4/5; 1/1] START colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7\n",
      "[CV 4/5; 1/1] END colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7;, score=0.381 total time=   4.5s\n",
      "[CV 5/5; 1/1] START colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7\n",
      "[CV 5/5; 1/1] END colsample_bytree=0.6, learning_rate=0.013872676858540168, max_depth=110, min_child_samples=160, n_estimators=600, num_leaves=119, reg_alpha=1.0, scale_pos_weight=8, subsample=0.7;, score=0.427 total time=   4.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2,\n",
       "                                       objective=&#x27;binary&#x27;, verbose=-1),\n",
       "              n_iter=30, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;colsample_bytree&#x27;: (0.6, 1.0),\n",
       "                             &#x27;learning_rate&#x27;: (0.01, 0.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (80, 110),\n",
       "                             &#x27;min_child_samples&#x27;: (140, 160),\n",
       "                             &#x27;n_estimators&#x27;: (600, 1200),\n",
       "                             &#x27;num_leaves&#x27;: (100, 120), &#x27;reg_alpha&#x27;: (0.0, 1.0),\n",
       "                             &#x27;scale_pos_weight&#x27;: (5, 10),\n",
       "                             &#x27;subsample&#x27;: (0.7, 1.0)},\n",
       "              verbose=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2,\n",
       "                                       objective=&#x27;binary&#x27;, verbose=-1),\n",
       "              n_iter=30, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;colsample_bytree&#x27;: (0.6, 1.0),\n",
       "                             &#x27;learning_rate&#x27;: (0.01, 0.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (80, 110),\n",
       "                             &#x27;min_child_samples&#x27;: (140, 160),\n",
       "                             &#x27;n_estimators&#x27;: (600, 1200),\n",
       "                             &#x27;num_leaves&#x27;: (100, 120), &#x27;reg_alpha&#x27;: (0.0, 1.0),\n",
       "                             &#x27;scale_pos_weight&#x27;: (5, 10),\n",
       "                             &#x27;subsample&#x27;: (0.7, 1.0)},\n",
       "              verbose=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2, objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_error&#x27;, n_jobs=2, objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=LGBMClassifier(metric='binary_error', n_jobs=2,\n",
       "                                       objective='binary', verbose=-1),\n",
       "              n_iter=30, scoring='f1',\n",
       "              search_spaces={'colsample_bytree': (0.6, 1.0),\n",
       "                             'learning_rate': (0.01, 0.1, 'log-uniform'),\n",
       "                             'max_depth': (80, 110),\n",
       "                             'min_child_samples': (140, 160),\n",
       "                             'n_estimators': (600, 1200),\n",
       "                             'num_leaves': (100, 120), 'reg_alpha': (0.0, 1.0),\n",
       "                             'scale_pos_weight': (5, 10),\n",
       "                             'subsample': (0.7, 1.0)},\n",
       "              verbose=100)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the simplified hyperparameter configuration space\n",
    "param_space = {\n",
    "    'num_leaves': (100,120),\n",
    "    'max_depth': (80,110),\n",
    "    'min_child_samples': (140, 160),\n",
    "    'subsample': (0.7, 1.0),\n",
    "    'colsample_bytree': (0.6, 1.0),\n",
    "    'scale_pos_weight': (5, 10),\n",
    "    'learning_rate': (0.01, 0.1, 'log-uniform'),\n",
    "    'n_estimators': (600, 1200),\n",
    "    'reg_alpha': (0.0, 1.0),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_error',\n",
    "        n_jobs=2,\n",
    "        verbose= -1\n",
    "    ),\n",
    "    search_spaces=param_space,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    n_iter=30,\n",
    "    verbose=100,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "opt.fit(Bow_features, labels_d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4111488885340888"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bytree', 0.6915100711795957),\n",
       "             ('learning_rate', 0.010355565762216848),\n",
       "             ('max_depth', 80),\n",
       "             ('min_child_samples', 143),\n",
       "             ('n_estimators', 901),\n",
       "             ('num_leaves', 100),\n",
       "             ('reg_alpha', 0.947914181540724),\n",
       "             ('scale_pos_weight', 7),\n",
       "             ('subsample', 0.7806775665122635)])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1cb66021b50>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = opt.best_params_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Manually train a model using the best params\n",
    "clf = lgb.LGBMClassifier(**best_params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predicted classes\n",
    "y_val_pred_class = [1 if x >= 0.5 else 0 for x in clf.predict(X_test)]\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_val_pred_class)\n",
    "\n",
    "#Save model\n",
    "clf.booster_.save_model('domain2_model.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86      2544\n",
      "           1       0.34      0.59      0.43       436\n",
      "\n",
      "    accuracy                           0.77      2980\n",
      "   macro avg       0.63      0.70      0.64      2980\n",
      "weighted avg       0.83      0.77      0.79      2980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162112\n",
      "[LightGBM] [Info] Number of data points in the train set: 11920, number of used features: 2171\n",
      "[LightGBM] [Info] Start training from score 0.143792\n",
      "[1]\tvalid_0's l2: 0.12454\n",
      "[2]\tvalid_0's l2: 0.124207\n",
      "[3]\tvalid_0's l2: 0.123862\n",
      "[4]\tvalid_0's l2: 0.123668\n",
      "[5]\tvalid_0's l2: 0.12336\n",
      "[6]\tvalid_0's l2: 0.123078\n",
      "[7]\tvalid_0's l2: 0.122752\n",
      "[8]\tvalid_0's l2: 0.122563\n",
      "[9]\tvalid_0's l2: 0.122279\n",
      "[10]\tvalid_0's l2: 0.122182\n",
      "[11]\tvalid_0's l2: 0.121908\n",
      "[12]\tvalid_0's l2: 0.121738\n",
      "[13]\tvalid_0's l2: 0.12146\n",
      "[14]\tvalid_0's l2: 0.121204\n",
      "[15]\tvalid_0's l2: 0.120948\n",
      "[16]\tvalid_0's l2: 0.120745\n",
      "[17]\tvalid_0's l2: 0.120582\n",
      "[18]\tvalid_0's l2: 0.120358\n",
      "[19]\tvalid_0's l2: 0.120078\n",
      "[20]\tvalid_0's l2: 0.11981\n",
      "[21]\tvalid_0's l2: 0.119687\n",
      "[22]\tvalid_0's l2: 0.119463\n",
      "[23]\tvalid_0's l2: 0.119307\n",
      "[24]\tvalid_0's l2: 0.119097\n",
      "[25]\tvalid_0's l2: 0.118855\n",
      "[26]\tvalid_0's l2: 0.118598\n",
      "[27]\tvalid_0's l2: 0.118385\n",
      "[28]\tvalid_0's l2: 0.118179\n",
      "[29]\tvalid_0's l2: 0.117946\n",
      "[30]\tvalid_0's l2: 0.11778\n",
      "[31]\tvalid_0's l2: 0.117572\n",
      "[32]\tvalid_0's l2: 0.117458\n",
      "[33]\tvalid_0's l2: 0.117304\n",
      "[34]\tvalid_0's l2: 0.117177\n",
      "[35]\tvalid_0's l2: 0.117025\n",
      "[36]\tvalid_0's l2: 0.116894\n",
      "[37]\tvalid_0's l2: 0.11672\n",
      "[38]\tvalid_0's l2: 0.116566\n",
      "[39]\tvalid_0's l2: 0.116405\n",
      "[40]\tvalid_0's l2: 0.11621\n",
      "[41]\tvalid_0's l2: 0.11608\n",
      "[42]\tvalid_0's l2: 0.115921\n",
      "[43]\tvalid_0's l2: 0.115785\n",
      "[44]\tvalid_0's l2: 0.115726\n",
      "[45]\tvalid_0's l2: 0.115599\n",
      "[46]\tvalid_0's l2: 0.115465\n",
      "[47]\tvalid_0's l2: 0.115369\n",
      "[48]\tvalid_0's l2: 0.115245\n",
      "[49]\tvalid_0's l2: 0.115176\n",
      "[50]\tvalid_0's l2: 0.114999\n",
      "[51]\tvalid_0's l2: 0.114858\n",
      "[52]\tvalid_0's l2: 0.114801\n",
      "[53]\tvalid_0's l2: 0.11467\n",
      "[54]\tvalid_0's l2: 0.114602\n",
      "[55]\tvalid_0's l2: 0.114458\n",
      "[56]\tvalid_0's l2: 0.114299\n",
      "[57]\tvalid_0's l2: 0.114184\n",
      "[58]\tvalid_0's l2: 0.114117\n",
      "[59]\tvalid_0's l2: 0.114082\n",
      "[60]\tvalid_0's l2: 0.113985\n",
      "[61]\tvalid_0's l2: 0.113878\n",
      "[62]\tvalid_0's l2: 0.113785\n",
      "[63]\tvalid_0's l2: 0.113705\n",
      "[64]\tvalid_0's l2: 0.113595\n",
      "[65]\tvalid_0's l2: 0.1135\n",
      "[66]\tvalid_0's l2: 0.113375\n",
      "[67]\tvalid_0's l2: 0.113313\n",
      "[68]\tvalid_0's l2: 0.113223\n",
      "[69]\tvalid_0's l2: 0.11314\n",
      "[70]\tvalid_0's l2: 0.113056\n",
      "[71]\tvalid_0's l2: 0.112965\n",
      "[72]\tvalid_0's l2: 0.112872\n",
      "[73]\tvalid_0's l2: 0.112764\n",
      "[74]\tvalid_0's l2: 0.112632\n",
      "[75]\tvalid_0's l2: 0.112623\n",
      "[76]\tvalid_0's l2: 0.112501\n",
      "[77]\tvalid_0's l2: 0.112413\n",
      "[78]\tvalid_0's l2: 0.112343\n",
      "[79]\tvalid_0's l2: 0.112239\n",
      "[80]\tvalid_0's l2: 0.112179\n",
      "[81]\tvalid_0's l2: 0.112103\n",
      "[82]\tvalid_0's l2: 0.112002\n",
      "[83]\tvalid_0's l2: 0.111927\n",
      "[84]\tvalid_0's l2: 0.11184\n",
      "[85]\tvalid_0's l2: 0.111764\n",
      "[86]\tvalid_0's l2: 0.111746\n",
      "[87]\tvalid_0's l2: 0.111667\n",
      "[88]\tvalid_0's l2: 0.111624\n",
      "[89]\tvalid_0's l2: 0.111596\n",
      "[90]\tvalid_0's l2: 0.11152\n",
      "[91]\tvalid_0's l2: 0.111484\n",
      "[92]\tvalid_0's l2: 0.111412\n",
      "[93]\tvalid_0's l2: 0.11137\n",
      "[94]\tvalid_0's l2: 0.111344\n",
      "[95]\tvalid_0's l2: 0.111269\n",
      "[96]\tvalid_0's l2: 0.111204\n",
      "[97]\tvalid_0's l2: 0.111156\n",
      "[98]\tvalid_0's l2: 0.111128\n",
      "[99]\tvalid_0's l2: 0.111076\n",
      "[100]\tvalid_0's l2: 0.111061\n",
      "[101]\tvalid_0's l2: 0.11102\n",
      "[102]\tvalid_0's l2: 0.11099\n",
      "[103]\tvalid_0's l2: 0.110942\n",
      "[104]\tvalid_0's l2: 0.110889\n",
      "[105]\tvalid_0's l2: 0.110827\n",
      "[106]\tvalid_0's l2: 0.110769\n",
      "[107]\tvalid_0's l2: 0.110685\n",
      "[108]\tvalid_0's l2: 0.110639\n",
      "[109]\tvalid_0's l2: 0.110576\n",
      "[110]\tvalid_0's l2: 0.110561\n",
      "[111]\tvalid_0's l2: 0.110511\n",
      "[112]\tvalid_0's l2: 0.110463\n",
      "[113]\tvalid_0's l2: 0.110434\n",
      "[114]\tvalid_0's l2: 0.110378\n",
      "[115]\tvalid_0's l2: 0.110337\n",
      "[116]\tvalid_0's l2: 0.11031\n",
      "[117]\tvalid_0's l2: 0.110253\n",
      "[118]\tvalid_0's l2: 0.11018\n",
      "[119]\tvalid_0's l2: 0.110139\n",
      "[120]\tvalid_0's l2: 0.110077\n",
      "[121]\tvalid_0's l2: 0.110043\n",
      "[122]\tvalid_0's l2: 0.109964\n",
      "[123]\tvalid_0's l2: 0.109943\n",
      "[124]\tvalid_0's l2: 0.109912\n",
      "[125]\tvalid_0's l2: 0.109874\n",
      "[126]\tvalid_0's l2: 0.109823\n",
      "[127]\tvalid_0's l2: 0.109784\n",
      "[128]\tvalid_0's l2: 0.109731\n",
      "[129]\tvalid_0's l2: 0.10971\n",
      "[130]\tvalid_0's l2: 0.109703\n",
      "[131]\tvalid_0's l2: 0.109628\n",
      "[132]\tvalid_0's l2: 0.109598\n",
      "[133]\tvalid_0's l2: 0.109571\n",
      "[134]\tvalid_0's l2: 0.109548\n",
      "[135]\tvalid_0's l2: 0.109531\n",
      "[136]\tvalid_0's l2: 0.109505\n",
      "[137]\tvalid_0's l2: 0.109493\n",
      "[138]\tvalid_0's l2: 0.109473\n",
      "[139]\tvalid_0's l2: 0.109432\n",
      "[140]\tvalid_0's l2: 0.109403\n",
      "[141]\tvalid_0's l2: 0.109362\n",
      "[142]\tvalid_0's l2: 0.109357\n",
      "[143]\tvalid_0's l2: 0.109315\n",
      "[144]\tvalid_0's l2: 0.109293\n",
      "[145]\tvalid_0's l2: 0.109251\n",
      "[146]\tvalid_0's l2: 0.109226\n",
      "[147]\tvalid_0's l2: 0.109196\n",
      "[148]\tvalid_0's l2: 0.109172\n",
      "[149]\tvalid_0's l2: 0.109112\n",
      "[150]\tvalid_0's l2: 0.109081\n",
      "[151]\tvalid_0's l2: 0.109052\n",
      "[152]\tvalid_0's l2: 0.109046\n",
      "[153]\tvalid_0's l2: 0.109009\n",
      "[154]\tvalid_0's l2: 0.108977\n",
      "[155]\tvalid_0's l2: 0.108947\n",
      "[156]\tvalid_0's l2: 0.10892\n",
      "[157]\tvalid_0's l2: 0.108872\n",
      "[158]\tvalid_0's l2: 0.108858\n",
      "[159]\tvalid_0's l2: 0.108824\n",
      "[160]\tvalid_0's l2: 0.108796\n",
      "[161]\tvalid_0's l2: 0.108751\n",
      "[162]\tvalid_0's l2: 0.108736\n",
      "[163]\tvalid_0's l2: 0.108721\n",
      "[164]\tvalid_0's l2: 0.108688\n",
      "[165]\tvalid_0's l2: 0.108636\n",
      "[166]\tvalid_0's l2: 0.108631\n",
      "[167]\tvalid_0's l2: 0.108595\n",
      "[168]\tvalid_0's l2: 0.10859\n",
      "[169]\tvalid_0's l2: 0.108587\n",
      "[170]\tvalid_0's l2: 0.108578\n",
      "[171]\tvalid_0's l2: 0.108556\n",
      "[172]\tvalid_0's l2: 0.108518\n",
      "[173]\tvalid_0's l2: 0.108488\n",
      "[174]\tvalid_0's l2: 0.108445\n",
      "[175]\tvalid_0's l2: 0.10842\n",
      "[176]\tvalid_0's l2: 0.108396\n",
      "[177]\tvalid_0's l2: 0.108357\n",
      "[178]\tvalid_0's l2: 0.108319\n",
      "[179]\tvalid_0's l2: 0.108296\n",
      "[180]\tvalid_0's l2: 0.108281\n",
      "[181]\tvalid_0's l2: 0.108235\n",
      "[182]\tvalid_0's l2: 0.108203\n",
      "[183]\tvalid_0's l2: 0.108179\n",
      "[184]\tvalid_0's l2: 0.108161\n",
      "[185]\tvalid_0's l2: 0.108159\n",
      "[186]\tvalid_0's l2: 0.10814\n",
      "[187]\tvalid_0's l2: 0.108121\n",
      "[188]\tvalid_0's l2: 0.108092\n",
      "[189]\tvalid_0's l2: 0.108047\n",
      "[190]\tvalid_0's l2: 0.108023\n",
      "[191]\tvalid_0's l2: 0.107995\n",
      "[192]\tvalid_0's l2: 0.107977\n",
      "[193]\tvalid_0's l2: 0.107975\n",
      "[194]\tvalid_0's l2: 0.107964\n",
      "[195]\tvalid_0's l2: 0.107951\n",
      "[196]\tvalid_0's l2: 0.107928\n",
      "[197]\tvalid_0's l2: 0.107936\n",
      "[198]\tvalid_0's l2: 0.107928\n",
      "[199]\tvalid_0's l2: 0.10793\n",
      "[200]\tvalid_0's l2: 0.107897\n",
      "[201]\tvalid_0's l2: 0.107878\n",
      "[202]\tvalid_0's l2: 0.107852\n",
      "[203]\tvalid_0's l2: 0.107873\n",
      "[204]\tvalid_0's l2: 0.107845\n",
      "[205]\tvalid_0's l2: 0.107808\n",
      "[206]\tvalid_0's l2: 0.107771\n",
      "[207]\tvalid_0's l2: 0.107781\n",
      "[208]\tvalid_0's l2: 0.10776\n",
      "[209]\tvalid_0's l2: 0.107751\n",
      "[210]\tvalid_0's l2: 0.107705\n",
      "[211]\tvalid_0's l2: 0.107692\n",
      "[212]\tvalid_0's l2: 0.107719\n",
      "[213]\tvalid_0's l2: 0.107713\n",
      "[214]\tvalid_0's l2: 0.107687\n",
      "[215]\tvalid_0's l2: 0.107655\n",
      "[216]\tvalid_0's l2: 0.107658\n",
      "[217]\tvalid_0's l2: 0.107654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[218]\tvalid_0's l2: 0.107627\n",
      "[219]\tvalid_0's l2: 0.107614\n",
      "[220]\tvalid_0's l2: 0.107578\n",
      "[221]\tvalid_0's l2: 0.107557\n",
      "[222]\tvalid_0's l2: 0.107557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[223]\tvalid_0's l2: 0.107571\n",
      "[224]\tvalid_0's l2: 0.107566\n",
      "[225]\tvalid_0's l2: 0.107518\n",
      "[226]\tvalid_0's l2: 0.107494\n",
      "[227]\tvalid_0's l2: 0.107486\n",
      "[228]\tvalid_0's l2: 0.107443\n",
      "[229]\tvalid_0's l2: 0.107433\n",
      "[230]\tvalid_0's l2: 0.107446\n",
      "[231]\tvalid_0's l2: 0.107438\n",
      "[232]\tvalid_0's l2: 0.107398\n",
      "[233]\tvalid_0's l2: 0.107375\n",
      "[234]\tvalid_0's l2: 0.107358\n",
      "[235]\tvalid_0's l2: 0.107332\n",
      "[236]\tvalid_0's l2: 0.10732\n",
      "[237]\tvalid_0's l2: 0.107312\n",
      "[238]\tvalid_0's l2: 0.107295\n",
      "[239]\tvalid_0's l2: 0.107283\n",
      "[240]\tvalid_0's l2: 0.107281\n",
      "[241]\tvalid_0's l2: 0.107249\n",
      "[242]\tvalid_0's l2: 0.107244\n",
      "[243]\tvalid_0's l2: 0.107234\n",
      "[244]\tvalid_0's l2: 0.107246\n",
      "[245]\tvalid_0's l2: 0.107233\n",
      "[246]\tvalid_0's l2: 0.107234\n",
      "[247]\tvalid_0's l2: 0.107214\n",
      "[248]\tvalid_0's l2: 0.107204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[249]\tvalid_0's l2: 0.107205\n",
      "[250]\tvalid_0's l2: 0.107213\n",
      "[251]\tvalid_0's l2: 0.107217\n",
      "[252]\tvalid_0's l2: 0.107203\n",
      "[253]\tvalid_0's l2: 0.107185\n",
      "[254]\tvalid_0's l2: 0.107172\n",
      "[255]\tvalid_0's l2: 0.107182\n",
      "[256]\tvalid_0's l2: 0.107179\n",
      "[257]\tvalid_0's l2: 0.107159\n",
      "[258]\tvalid_0's l2: 0.107155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[259]\tvalid_0's l2: 0.107172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[260]\tvalid_0's l2: 0.107171\n",
      "[261]\tvalid_0's l2: 0.107158\n",
      "[262]\tvalid_0's l2: 0.107147\n",
      "[263]\tvalid_0's l2: 0.107132\n",
      "[264]\tvalid_0's l2: 0.107118\n",
      "[265]\tvalid_0's l2: 0.107104\n",
      "[266]\tvalid_0's l2: 0.107088\n",
      "[267]\tvalid_0's l2: 0.107057\n",
      "[268]\tvalid_0's l2: 0.107063\n",
      "[269]\tvalid_0's l2: 0.107059\n",
      "[270]\tvalid_0's l2: 0.107064\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[271]\tvalid_0's l2: 0.107047\n",
      "[272]\tvalid_0's l2: 0.107032\n",
      "[273]\tvalid_0's l2: 0.107016\n",
      "[274]\tvalid_0's l2: 0.107009\n",
      "[275]\tvalid_0's l2: 0.107013\n",
      "[276]\tvalid_0's l2: 0.107023\n",
      "[277]\tvalid_0's l2: 0.107017\n",
      "[278]\tvalid_0's l2: 0.106998\n",
      "[279]\tvalid_0's l2: 0.106973\n",
      "[280]\tvalid_0's l2: 0.106966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[281]\tvalid_0's l2: 0.10697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[282]\tvalid_0's l2: 0.10697\n",
      "[283]\tvalid_0's l2: 0.106958\n",
      "[284]\tvalid_0's l2: 0.106949\n",
      "[285]\tvalid_0's l2: 0.106939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[286]\tvalid_0's l2: 0.106933\n",
      "[287]\tvalid_0's l2: 0.106928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[288]\tvalid_0's l2: 0.106923\n",
      "[289]\tvalid_0's l2: 0.106922\n",
      "[290]\tvalid_0's l2: 0.106914\n",
      "[291]\tvalid_0's l2: 0.106906\n",
      "[292]\tvalid_0's l2: 0.106893\n",
      "[293]\tvalid_0's l2: 0.106888\n",
      "[294]\tvalid_0's l2: 0.106887\n",
      "[295]\tvalid_0's l2: 0.106902\n",
      "[296]\tvalid_0's l2: 0.106919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[297]\tvalid_0's l2: 0.106913\n",
      "[298]\tvalid_0's l2: 0.106902\n",
      "[299]\tvalid_0's l2: 0.106872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's l2: 0.10687\n",
      "[301]\tvalid_0's l2: 0.106868\n",
      "[302]\tvalid_0's l2: 0.106863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[303]\tvalid_0's l2: 0.106872\n",
      "[304]\tvalid_0's l2: 0.10687\n",
      "[305]\tvalid_0's l2: 0.106857\n",
      "[306]\tvalid_0's l2: 0.106845\n",
      "[307]\tvalid_0's l2: 0.106838\n",
      "[308]\tvalid_0's l2: 0.106832\n",
      "[309]\tvalid_0's l2: 0.106808\n",
      "[310]\tvalid_0's l2: 0.106802\n",
      "[311]\tvalid_0's l2: 0.106803\n",
      "[312]\tvalid_0's l2: 0.106792\n",
      "[313]\tvalid_0's l2: 0.106773\n",
      "[314]\tvalid_0's l2: 0.106781\n",
      "[315]\tvalid_0's l2: 0.106796\n",
      "[316]\tvalid_0's l2: 0.106809\n",
      "[317]\tvalid_0's l2: 0.1068\n",
      "[318]\tvalid_0's l2: 0.106802\n",
      "[319]\tvalid_0's l2: 0.106797\n",
      "[320]\tvalid_0's l2: 0.106809\n",
      "[321]\tvalid_0's l2: 0.106796\n",
      "[322]\tvalid_0's l2: 0.106769\n",
      "[323]\tvalid_0's l2: 0.106776\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[324]\tvalid_0's l2: 0.106766\n",
      "[325]\tvalid_0's l2: 0.106744\n",
      "[326]\tvalid_0's l2: 0.106724\n",
      "[327]\tvalid_0's l2: 0.10672\n",
      "[328]\tvalid_0's l2: 0.106709\n",
      "[329]\tvalid_0's l2: 0.106682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\tvalid_0's l2: 0.106673\n",
      "[331]\tvalid_0's l2: 0.106673\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[332]\tvalid_0's l2: 0.106671\n",
      "[333]\tvalid_0's l2: 0.106658\n",
      "[334]\tvalid_0's l2: 0.106645\n",
      "[335]\tvalid_0's l2: 0.106646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[336]\tvalid_0's l2: 0.106655\n",
      "[337]\tvalid_0's l2: 0.106656\n",
      "[338]\tvalid_0's l2: 0.106638\n",
      "[339]\tvalid_0's l2: 0.106615\n",
      "[340]\tvalid_0's l2: 0.106626\n",
      "[341]\tvalid_0's l2: 0.106608\n",
      "[342]\tvalid_0's l2: 0.106602\n",
      "[343]\tvalid_0's l2: 0.106578\n",
      "[344]\tvalid_0's l2: 0.106563\n",
      "[345]\tvalid_0's l2: 0.106558\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[346]\tvalid_0's l2: 0.106562\n",
      "[347]\tvalid_0's l2: 0.106552\n",
      "[348]\tvalid_0's l2: 0.106547\n",
      "[349]\tvalid_0's l2: 0.106548\n",
      "[350]\tvalid_0's l2: 0.106528\n",
      "[351]\tvalid_0's l2: 0.106532\n",
      "[352]\tvalid_0's l2: 0.106525\n",
      "[353]\tvalid_0's l2: 0.10652\n",
      "[354]\tvalid_0's l2: 0.106532\n",
      "[355]\tvalid_0's l2: 0.106521\n",
      "[356]\tvalid_0's l2: 0.106506\n",
      "[357]\tvalid_0's l2: 0.10651\n",
      "[358]\tvalid_0's l2: 0.106513\n",
      "[359]\tvalid_0's l2: 0.1065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[360]\tvalid_0's l2: 0.106497\n",
      "[361]\tvalid_0's l2: 0.106486\n",
      "[362]\tvalid_0's l2: 0.106472\n",
      "[363]\tvalid_0's l2: 0.106457\n",
      "[364]\tvalid_0's l2: 0.106446\n",
      "[365]\tvalid_0's l2: 0.106423\n",
      "[366]\tvalid_0's l2: 0.106411\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[367]\tvalid_0's l2: 0.106402\n",
      "[368]\tvalid_0's l2: 0.106398\n",
      "[369]\tvalid_0's l2: 0.106402\n",
      "[370]\tvalid_0's l2: 0.106403\n",
      "[371]\tvalid_0's l2: 0.106395\n",
      "[372]\tvalid_0's l2: 0.106393\n",
      "[373]\tvalid_0's l2: 0.106391\n",
      "[374]\tvalid_0's l2: 0.106396\n",
      "[375]\tvalid_0's l2: 0.106391\n",
      "[376]\tvalid_0's l2: 0.106373\n",
      "[377]\tvalid_0's l2: 0.106387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[378]\tvalid_0's l2: 0.106365\n",
      "[379]\tvalid_0's l2: 0.106345\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\tvalid_0's l2: 0.106336\n",
      "[381]\tvalid_0's l2: 0.106312\n",
      "[382]\tvalid_0's l2: 0.106303\n",
      "[383]\tvalid_0's l2: 0.106299\n",
      "[384]\tvalid_0's l2: 0.106294\n",
      "[385]\tvalid_0's l2: 0.106297\n",
      "[386]\tvalid_0's l2: 0.106298\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[387]\tvalid_0's l2: 0.1063\n",
      "[388]\tvalid_0's l2: 0.106295\n",
      "[389]\tvalid_0's l2: 0.106275\n",
      "[390]\tvalid_0's l2: 0.106258\n",
      "[391]\tvalid_0's l2: 0.106246\n",
      "[392]\tvalid_0's l2: 0.106232\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[393]\tvalid_0's l2: 0.106228\n",
      "[394]\tvalid_0's l2: 0.106233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[395]\tvalid_0's l2: 0.106237\n",
      "[396]\tvalid_0's l2: 0.106232\n",
      "[397]\tvalid_0's l2: 0.106235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[398]\tvalid_0's l2: 0.106237\n",
      "[399]\tvalid_0's l2: 0.10624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's l2: 0.106238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[401]\tvalid_0's l2: 0.106245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[402]\tvalid_0's l2: 0.106244\n",
      "[403]\tvalid_0's l2: 0.106252\n",
      "[404]\tvalid_0's l2: 0.106248\n",
      "[405]\tvalid_0's l2: 0.106255\n",
      "[406]\tvalid_0's l2: 0.10624\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[407]\tvalid_0's l2: 0.106248\n",
      "[408]\tvalid_0's l2: 0.106247\n",
      "[409]\tvalid_0's l2: 0.106254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[410]\tvalid_0's l2: 0.106256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[411]\tvalid_0's l2: 0.10625\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[412]\tvalid_0's l2: 0.106254\n",
      "[413]\tvalid_0's l2: 0.106257\n",
      "[414]\tvalid_0's l2: 0.106258\n",
      "[415]\tvalid_0's l2: 0.106248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[416]\tvalid_0's l2: 0.106251\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[417]\tvalid_0's l2: 0.10625\n",
      "[418]\tvalid_0's l2: 0.106245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[419]\tvalid_0's l2: 0.106246\n",
      "[420]\tvalid_0's l2: 0.106241\n",
      "[421]\tvalid_0's l2: 0.106236\n",
      "[422]\tvalid_0's l2: 0.106251\n",
      "[423]\tvalid_0's l2: 0.106241\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[424]\tvalid_0's l2: 0.106236\n",
      "[425]\tvalid_0's l2: 0.106235\n",
      "[426]\tvalid_0's l2: 0.106227\n",
      "[427]\tvalid_0's l2: 0.106228\n",
      "[428]\tvalid_0's l2: 0.106241\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[429]\tvalid_0's l2: 0.106239\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[430]\tvalid_0's l2: 0.106223\n",
      "[431]\tvalid_0's l2: 0.106217\n",
      "[432]\tvalid_0's l2: 0.106214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[433]\tvalid_0's l2: 0.10621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[434]\tvalid_0's l2: 0.10621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[435]\tvalid_0's l2: 0.106207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[436]\tvalid_0's l2: 0.106212\n",
      "[437]\tvalid_0's l2: 0.106211\n",
      "[438]\tvalid_0's l2: 0.106202\n",
      "[439]\tvalid_0's l2: 0.106191\n",
      "[440]\tvalid_0's l2: 0.106188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[441]\tvalid_0's l2: 0.106195\n",
      "[442]\tvalid_0's l2: 0.106183\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[443]\tvalid_0's l2: 0.106191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[444]\tvalid_0's l2: 0.106186\n",
      "[445]\tvalid_0's l2: 0.106172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[446]\tvalid_0's l2: 0.106165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[447]\tvalid_0's l2: 0.106157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[448]\tvalid_0's l2: 0.106157\n",
      "[449]\tvalid_0's l2: 0.10617\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\tvalid_0's l2: 0.106178\n",
      "[451]\tvalid_0's l2: 0.106184\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[452]\tvalid_0's l2: 0.10619\n",
      "[453]\tvalid_0's l2: 0.106193\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[454]\tvalid_0's l2: 0.106201\n",
      "[455]\tvalid_0's l2: 0.106205\n",
      "[456]\tvalid_0's l2: 0.106195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[457]\tvalid_0's l2: 0.106191\n",
      "[458]\tvalid_0's l2: 0.106177\n",
      "[459]\tvalid_0's l2: 0.106174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[460]\tvalid_0's l2: 0.106175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[461]\tvalid_0's l2: 0.106171\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[462]\tvalid_0's l2: 0.106177\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[463]\tvalid_0's l2: 0.106176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[464]\tvalid_0's l2: 0.106168\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[465]\tvalid_0's l2: 0.106159\n",
      "[466]\tvalid_0's l2: 0.106143\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[467]\tvalid_0's l2: 0.106157\n",
      "[468]\tvalid_0's l2: 0.106157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[469]\tvalid_0's l2: 0.106174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\tvalid_0's l2: 0.106173\n",
      "f1s: 0.09787234042553193\n",
      "Precision: 0.6764705882352942\n",
      "AUC: 0.7754601580982055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create a LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.72,\n",
    "    'learning_rate': 0.01642,\n",
    "    'max_depth': 23,\n",
    "    'min_child_samples': 60,\n",
    "    'num_leaves': 50,\n",
    "    'n_estimators': 470,\n",
    "    'scale_pos_weight': 8,\n",
    "    'subsample': 0.93446,\n",
    "    'reg_alpha': 0.30421732656825395\n",
    "\n",
    "}\n",
    "bst = lgb.train(best_params, train_data, valid_sets=[test_data])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bst.predict(X_test)\n",
    "# Convert to binary output\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "f1s = f1_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "auc = roc_auc_score(y_test, y_pred)  # y_pred is the probability, not the binary output\n",
    "\n",
    "print(f\"f1s: {f1s}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052752293577981654"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
