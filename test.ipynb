{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Masking\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "model_domain2 = lgb.Booster(model_file='domain2_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_domain = load_model(\"model_domain\")\n",
    "\n",
    "model_domain1 = load_model(\"model_domain1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = []\n",
    "test_texts_tfidf = []\n",
    "zeros_in_text = []\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "# Open file for reading\n",
    "with open('test_set.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)        \n",
    "        text_without_zeros = []\n",
    "        count_zeros = 0\n",
    "        for id in obj['text']:\n",
    "            if id != 0 :\n",
    "                text_without_zeros.append(id)\n",
    "            else:\n",
    "                count_zeros += 1\n",
    "        test_texts_tfidf.append(obj['text'])\n",
    "        test_texts.append(text_without_zeros)\n",
    "        zeros_in_text.append(count_zeros)\n",
    "\n",
    "padded_texts = pad_sequences(test_texts, padding='pre', value=0)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None)  \n",
    "# Load it back\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "test_texts_tfidf = tfidf.transform(test_texts_tfidf)\n",
    "zeros_in_text = np.array(zeros_in_text).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model_domain.predict([padded_texts, zeros_in_text])\n",
    "\n",
    "# Interpret predictions\n",
    "domain_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 20s 553ms/step\n"
     ]
    }
   ],
   "source": [
    "model1_predictions = model_domain1.predict([padded_texts, zeros_in_text])\n",
    "# Interpret predictions\n",
    "model1_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "model2_predictions = model_domain2.predict(test_texts_tfidf)\n",
    "# Convert to binary output\n",
    "model2_predictions = [1 if pred > 0.5 else 0 for pred in model2_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions =[]\n",
    "count_domain_1 = 0\n",
    "count_domain_2 = 0\n",
    "for i in range(len(domain_predictions)):\n",
    "    domain = domain_predictions[i]\n",
    "    if domain == 0:\n",
    "        final_predictions.append(model1_predictions[i])\n",
    "        count_domain_1+=1\n",
    "    else:\n",
    "        final_predictions.append(model2_predictions[i])\n",
    "        count_domain_2+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_df = pd.DataFrame({\"id\":list(range(len(final_predictions))), \"class\": final_predictions})\n",
    "output_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_domain_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
