{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Masking\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "features_d1 = []\n",
    "labels_d1 = []\n",
    "labels_domain = []\n",
    "# Open file for reading\n",
    "with open('domain1_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d1.append(obj['text'])\n",
    "        labels_d1.append(obj['label'])\n",
    "\n",
    "        if obj['label']  == 0 :\n",
    "            labels_domain.append(7)\n",
    "        else:\n",
    "            labels_domain.append(8)\n",
    "\n",
    "features_d2 = []\n",
    "labels_d2 = []\n",
    "# Open file for reading\n",
    "with open('domain2_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d2.append(obj['text'])\n",
    "        labels_d2.append(obj['label'])\n",
    "        if obj['label'] == 0:\n",
    "            labels_domain.append(int(obj['model']))\n",
    "        else:\n",
    "            labels_domain.append(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_d1 + features_d2\n",
    "labels = labels_d1 + labels_d2\n",
    "new_features = []\n",
    "for text in features:\n",
    "    new_text = [x + 1 for x in text]\n",
    "    new_features.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "padded_features = pad_sequences(new_features, padding='pre', value=0)\n",
    "labels_domain = to_categorical(labels_domain, num_classes=9)\n",
    "\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "X_train, X_test, y_label_train, y_label_test, y_domain_train, y_domain_test = train_test_split(\n",
    "    padded_features, labels, labels_domain, test_size=0.2, random_state=42\n",
    ")\n",
    "y_train = {'label': y_label_train, 'domain': y_domain_train}\n",
    "y_test = {'label': y_label_test, 'domain': y_domain_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(labels_domain, bins=range(min(labels_domain), max(labels_domain) + 2), align='left', alpha=0.7, color='blue')\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('Integer Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add title\n",
    "plt.title('Frequency of Each Integer Value')\n",
    "\n",
    "# Add integer labels to x-axis\n",
    "plt.xticks(range(min(labels_domain), max(labels_domain) + 1))\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = pad_sequences(new_features, padding='pre', value=0)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.sum(y_train[\"domain\"], axis=0) / len(y_train[\"domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06965843, 0.06882267, 0.06773256, 0.06849564, 0.02303779,\n",
       "       0.02274709, 0.05221657, 0.28175873, 0.3455305 ], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\test-c-lstm.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Flatten\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m class_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(y_train[\u001b[39m\"\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m class_weights \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m class_weights\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m normalized_weights \u001b[39m=\u001b[39m class_weights \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(class_weights)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional, concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "class_weights = np.sum(y_train[\"domain\"], axis=0) / len(y_train)\n",
    "class_weights = 1 / class_weights\n",
    "normalized_weights = class_weights / np.sum(class_weights)\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 with 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss, ...)\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = tf.constant(weights, dtype=tf.float32)\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probabilities of each sample sum to 1\n",
    "        y_pred /= tf.reduce_sum(y_pred, axis=-1, keepdims=True)\n",
    "        \n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        \n",
    "        # compute weighted loss\n",
    "        loss = y_true * tf.math.log(y_pred) * weights\n",
    "        loss = -tf.reduce_sum(loss, axis=-1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "vocab_size = 5000  # Vocabulary size\n",
    "embedding_dim = 100 # Embedding dimension\n",
    "n_classes = 2  # Binary classification for the main task\n",
    "n_domain_classes = 9  # Classification for the domain task\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
    "\n",
    "\n",
    "dropout_lstm_1 = Dropout(0.5)(embedding_layer)\n",
    "# LSTM Layer\n",
    "lstm_layer = Bidirectional(LSTM(32))(embedding_layer)\n",
    "dropout_lstm_2 = Dropout(0.5)(lstm_layer)\n",
    "\n",
    "lstm_output = Flatten()(dropout_lstm_2)\n",
    "\n",
    "# Conv1D Layer\n",
    "conv1d_layer_1 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding_layer)\n",
    "# Conv1D Layer\n",
    "conv1d_layer_2 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv1d_layer_1)\n",
    "\n",
    "\n",
    "global_max_pooling = GlobalMaxPooling1D()(conv1d_layer_2)\n",
    "\n",
    "#Dense\n",
    "cnn_output= Dense(32)(global_max_pooling)\n",
    "\n",
    "# Concatenate Layer\n",
    "concat_layer = concatenate([cnn_output, lstm_output])\n",
    "\n",
    "#Dense\n",
    "dense_layer = Dense(32, activation='relu')(concat_layer)\n",
    "\n",
    "\n",
    "\n",
    "# Task output\n",
    "task_output = Dense(n_classes, activation='sigmoid', name='label')(dense_layer)\n",
    "\n",
    "# Domain output\n",
    "domain_output = Dense(n_domain_classes, activation='softmax', name='domain')(dense_layer)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=input_layer, outputs=[task_output, domain_output])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'label': 'binary_crossentropy',\n",
    "                  'domain': weighted_categorical_crossentropy(normalized_weights)\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 12/215 [>.............................] - ETA: 10:19 - loss: 0.7820 - label_loss: 0.6638 - domain_loss: 0.1183 - label_accuracy: 0.6074 - domain_accuracy: 0.0775"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\test-c-lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdomain_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='domain_loss', patience=2, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, None, 100)    500000      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " masking_5 (Masking)            (None, None, 100)    0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, None, 32)     9632        ['masking_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, None, 32)     0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, None, 32)    0           ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 32)           8320        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 32)           0           ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           1056        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           1056        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 32)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 2)            66          ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " domain (Dense)                 (None, 9)            297         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 520,427\n",
      "Trainable params: 520,427\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 100\n",
    "n_classes = 2\n",
    "n_domain_classes = 9\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
    "\n",
    "# Masking Layer\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "\n",
    "# Conv1D Layer\n",
    "conv1d_layer = Conv1D(filters=32, kernel_size=3, activation='relu')(masking_layer)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout1 = Dropout(0.5)(conv1d_layer)\n",
    "\n",
    "# Max Pooling Layer\n",
    "max_pooling1 = MaxPooling1D(pool_size=2)(dropout1)\n",
    "\n",
    "# Shared LSTM Layer\n",
    "shared_lstm_layer = LSTM(32)(max_pooling1)\n",
    "\n",
    "# Dropout Layer (Shared)\n",
    "shared_dropout = Dropout(0.5)(shared_lstm_layer)\n",
    "\n",
    "# Binary Classification Specific Layers\n",
    "dense_binary = Dense(32, activation='relu')(shared_dropout)\n",
    "dropout_binary = Dropout(0.5)(dense_binary)\n",
    "output_binary = Dense(n_classes, activation='sigmoid', name='label')(dropout_binary)\n",
    "\n",
    "# Multi-class Classification Specific Layers\n",
    "dense_multi = Dense(32, activation='relu')(shared_dropout)\n",
    "dropout_multi = Dropout(0.5)(dense_multi)\n",
    "output_multi = Dense(n_domain_classes, activation='softmax', name='domain')(dropout_multi)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=input_layer, outputs=[output_binary, output_multi])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'label': 'binary_crossentropy', 'domain':  weighted_categorical_crossentropy(normalized_weights)}, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    500000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, None, 100)    0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 128)    117248      ['masking[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 128)    0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 64)           49408       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 2)            66          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " domain (Dense)                 (None, 2)            66          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 668,868\n",
      "Trainable params: 668,868\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000  # Vocabulary size\n",
    "embedding_dim = 100 # Embedding dimension\n",
    "n_classes = 2  # Binary classification for the main task\n",
    "n_domain_classes = 2  # Classification for the domain task\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "\n",
    "# Masking Layer\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer_1 = LSTM(128, return_sequences=True)(masking_layer)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout1 = Dropout(0.4)(lstm_layer_1)\n",
    "\n",
    "##LSTM Layer\n",
    "lstm_layer_2 = LSTM(64)(dropout1)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout2 = Dropout(0.4)(lstm_layer_2)\n",
    "\n",
    "dense = Dense(32, activation='relu')(dropout2)\n",
    "\n",
    "# Task output\n",
    "task_output = Dense(n_classes, activation='sigmoid', name='label')(dense)\n",
    "\n",
    "# Domain output\n",
    "domain_output = Dense(n_domain_classes, activation='sigmoid', name='domain')(dense)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=input_layer, outputs=[task_output, domain_output])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'label': 'binary_crossentropy',\n",
    "                  'domain': 'binary_crossentropy'\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((128, 533, 2) vs (128, 2)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\test-c-lstm.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdomain_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filelo6r7xtu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((128, 533, 2) vs (128, 2)).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='domain_loss', patience=2, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, None, 100)    500000      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " masking_8 (Masking)            (None, None, 100)    0           ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 (None, None, 32)     17024       ['masking_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, None, 32)     0           ['lstm_10[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, 16)           3136        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 2)            34          ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " domain (Dense)                 (None, 9)            153         ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 520,347\n",
      "Trainable params: 520,347\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 5000  # Vocabulary size\n",
    "embedding_dim = 100 # Embedding dimension\n",
    "n_classes = 2  # Binary classification for the main task\n",
    "n_domain_classes = 9  # Classification for the domain task\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
    "\n",
    "# Masking Layer\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer_1 = LSTM(32, return_sequences=True)(masking_layer)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout1 = Dropout(0.2)(lstm_layer_1)\n",
    "\n",
    "##LSTM Layer\n",
    "lstm_layer_2 = LSTM(16)(dropout1)\n",
    "\n",
    "# Task output\n",
    "task_output = Dense(n_classes, activation='sigmoid', name='label')(lstm_layer_2)\n",
    "\n",
    "# Domain output\n",
    "domain_output = Dense(n_domain_classes, activation='softmax', name='domain')(lstm_layer_2)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=input_layer, outputs=[task_output, domain_output])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'label': 'binary_crossentropy',\n",
    "                  'domain': weighted_categorical_crossentropy(normalized_weights)\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "215/215 [==============================] - 127s 569ms/step - loss: 0.5943 - label_loss: 0.4818 - domain_loss: 0.1125 - label_accuracy: 0.7919 - domain_accuracy: 0.2258 - val_loss: 0.7425 - val_label_loss: 0.6290 - val_domain_loss: 0.1135 - val_label_accuracy: 0.6525 - val_domain_accuracy: 0.0235\n",
      "Epoch 2/50\n",
      " 91/215 [===========>..................] - ETA: 1:14 - loss: 0.6354 - label_loss: 0.5212 - domain_loss: 0.1142 - label_accuracy: 0.7497 - domain_accuracy: 0.1588"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\test-c-lstm.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdomain_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='domain_loss', patience=2, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)       (None, None, 100)    500000      ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " masking_20 (Masking)           (None, None, 100)    0           ['embedding_20[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional_20 (Bidirectiona  (None, None, 64)    34048       ['masking_20[0][0]']             \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, None, 64)     0           ['bidirectional_20[0][0]']       \n",
      "                                                                                                  \n",
      " global_max_pooling1d_19 (Globa  (None, 64)          0           ['dropout_53[0][0]']             \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 32)           2080        ['global_max_pooling1d_19[0][0]']\n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 32)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 2)            66          ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " domain (Dense)                 (None, 9)            297         ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 536,491\n",
      "Trainable params: 536,491\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        y_pred = y_pred / tf.reduce_sum(y_pred, axis=-1, keepdims=True)\n",
    "        weighted_losses = y_true * tf.math.log(y_pred) * weights\n",
    "        loss = -tf.reduce_sum(weighted_losses, axis=-1)\n",
    "\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "# Constants\n",
    "vocab_size = 5000  # Vocabulary size\n",
    "embedding_dim = 100 # Embedding dimension\n",
    "n_classes = 2  # Binary classification for the main task\n",
    "n_domain_classes = 9  # Classification for the domain task\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
    "\n",
    "# Masking Layer\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "\n",
    "# LSTM Layer\n",
    "bilstm_layer = Bidirectional(LSTM(32, return_sequences=True))(masking_layer)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout2 = Dropout(0.5)(bilstm_layer)\n",
    "\n",
    "# GlobalMaxPooling Layer\n",
    "global_max_pooling = GlobalMaxPooling1D()(dropout2)\n",
    "# New Dense Layer\n",
    "dense_layer = Dense(32, activation='relu')(global_max_pooling)\n",
    "dense_dropout = Dropout(0.5)(dense_layer)\n",
    "\n",
    "# Task output\n",
    "task_output = Dense(n_classes, activation='sigmoid', name='label')(dense_dropout)\n",
    "\n",
    "# Domain output\n",
    "domain_output = Dense(n_domain_classes, activation='softmax', name='domain')(dense_dropout)\n",
    "\n",
    "# Combined model\n",
    "bilstm_model = Model(inputs=input_layer, outputs=[task_output, domain_output])\n",
    "\n",
    "\n",
    "\n",
    "weights_for_domain = [0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.04]  \n",
    "\n",
    "bilstm_model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'label': 'binary_crossentropy',\n",
    "                  'domain': weighted_categorical_crossentropy(weights_for_domain)\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "430/430 [==============================] - 201s 457ms/step - loss: 0.5185 - label_loss: 0.3670 - domain_loss: 0.1514 - label_accuracy: 0.8638 - domain_accuracy: 0.4871 - val_loss: 0.4659 - val_label_loss: 0.3393 - val_domain_loss: 0.1266 - val_label_accuracy: 0.9042 - val_domain_accuracy: 0.5705\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 200s 465ms/step - loss: 0.3788 - label_loss: 0.2600 - domain_loss: 0.1187 - label_accuracy: 0.9115 - domain_accuracy: 0.5745 - val_loss: 0.4290 - val_label_loss: 0.3130 - val_domain_loss: 0.1161 - val_label_accuracy: 0.9092 - val_domain_accuracy: 0.5983\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 169s 394ms/step - loss: 0.3290 - label_loss: 0.2194 - domain_loss: 0.1096 - label_accuracy: 0.9214 - domain_accuracy: 0.6072 - val_loss: 0.3977 - val_label_loss: 0.2892 - val_domain_loss: 0.1086 - val_label_accuracy: 0.9077 - val_domain_accuracy: 0.6243\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 152s 346ms/step - loss: 0.2939 - label_loss: 0.1899 - domain_loss: 0.1040 - label_accuracy: 0.9261 - domain_accuracy: 0.6257 - val_loss: 0.3756 - val_label_loss: 0.2686 - val_domain_loss: 0.1070 - val_label_accuracy: 0.9058 - val_domain_accuracy: 0.6246\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 150s 349ms/step - loss: 0.2636 - label_loss: 0.1639 - domain_loss: 0.0998 - label_accuracy: 0.9314 - domain_accuracy: 0.6435 - val_loss: 0.3582 - val_label_loss: 0.2557 - val_domain_loss: 0.1025 - val_label_accuracy: 0.9099 - val_domain_accuracy: 0.6291\n",
      "Epoch 6/50\n",
      "430/430 [==============================] - 158s 368ms/step - loss: 0.2437 - label_loss: 0.1466 - domain_loss: 0.0970 - label_accuracy: 0.9368 - domain_accuracy: 0.6519 - val_loss: 0.3600 - val_label_loss: 0.2595 - val_domain_loss: 0.1005 - val_label_accuracy: 0.9083 - val_domain_accuracy: 0.6343\n",
      "Epoch 7/50\n",
      "430/430 [==============================] - 151s 352ms/step - loss: 0.2205 - label_loss: 0.1262 - domain_loss: 0.0943 - label_accuracy: 0.9427 - domain_accuracy: 0.6613 - val_loss: 0.4027 - val_label_loss: 0.3012 - val_domain_loss: 0.1015 - val_label_accuracy: 0.8984 - val_domain_accuracy: 0.6270\n",
      "Epoch 8/50\n",
      " 61/430 [===>..........................] - ETA: 3:04 - loss: 0.1909 - label_loss: 0.0983 - domain_loss: 0.0927 - label_accuracy: 0.9518 - domain_accuracy: 0.6696"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\test-c-lstm.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/test-c-lstm.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bilstm_model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bilstm_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_30 (Embedding)       (None, None, 156)    780000      ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " masking_30 (Masking)           (None, None, 156)    0           ['embedding_30[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)                 (None, 32)           24192       ['masking_30[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 32)           0           ['lstm_30[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 16)           528         ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 16)           0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " label (Dense)                  (None, 2)            34          ['dropout_72[0][0]']             \n",
      "                                                                                                  \n",
      " domain (Dense)                 (None, 9)            153         ['dropout_72[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 804,907\n",
      "Trainable params: 804,907\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        y_pred = y_pred / tf.reduce_sum(y_pred, axis=-1, keepdims=True)\n",
    "        weighted_losses = y_true * tf.math.log(y_pred) * weights\n",
    "        loss = -tf.reduce_sum(weighted_losses, axis=-1)\n",
    "\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "# Constants\n",
    "vocab_size = 5000  # Vocabulary size\n",
    "embedding_dim = 156 # Embedding dimension\n",
    "n_classes = 2  # Binary classification for the main task\n",
    "n_domain_classes = 9  # Classification for the domain task\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding Layer\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
    "\n",
    "# Masking Layer\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(32)(masking_layer)\n",
    "\n",
    "# Dropout Layer\n",
    "dropout_lstm = Dropout(0.5)(lstm_layer)\n",
    "\n",
    "\n",
    "# New Dense Layer\n",
    "dense_layer = Dense(16, activation='relu')(dropout_lstm)\n",
    "dense_dropout = Dropout(0.3)(dense_layer)\n",
    "\n",
    "# Task output\n",
    "task_output = Dense(n_classes, activation='sigmoid', name='label')(dense_dropout)\n",
    "\n",
    "# Domain output\n",
    "domain_output = Dense(n_domain_classes, activation='softmax', name='domain')(dense_dropout)\n",
    "\n",
    "# Combined model\n",
    "lstm_model = Model(inputs=input_layer, outputs=[task_output, domain_output])\n",
    "\n",
    "\n",
    "\n",
    "weights_for_domain = [0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.05, 0.04]  \n",
    "\n",
    "lstm_model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'label': 'binary_crossentropy',\n",
    "                  'domain': weighted_categorical_crossentropy(weights_for_domain)\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Model summary\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "430/430 [==============================] - 85s 191ms/step - loss: 0.5403 - label_loss: 0.3889 - domain_loss: 0.1514 - label_accuracy: 0.8555 - domain_accuracy: 0.3940 - val_loss: 0.4044 - val_label_loss: 0.2772 - val_domain_loss: 0.1272 - val_label_accuracy: 0.8994 - val_domain_accuracy: 0.5506\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 80s 187ms/step - loss: 0.3921 - label_loss: 0.2630 - domain_loss: 0.1291 - label_accuracy: 0.9107 - domain_accuracy: 0.5351 - val_loss: 0.3842 - val_label_loss: 0.2645 - val_domain_loss: 0.1197 - val_label_accuracy: 0.9031 - val_domain_accuracy: 0.5674\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 78s 182ms/step - loss: 0.3328 - label_loss: 0.2094 - domain_loss: 0.1234 - label_accuracy: 0.9241 - domain_accuracy: 0.5612 - val_loss: 0.3862 - val_label_loss: 0.2678 - val_domain_loss: 0.1184 - val_label_accuracy: 0.9067 - val_domain_accuracy: 0.5844\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 79s 184ms/step - loss: 0.2865 - label_loss: 0.1677 - domain_loss: 0.1188 - label_accuracy: 0.9374 - domain_accuracy: 0.5836 - val_loss: 0.4233 - val_label_loss: 0.3062 - val_domain_loss: 0.1171 - val_label_accuracy: 0.9010 - val_domain_accuracy: 0.5842\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 74s 172ms/step - loss: 0.2578 - label_loss: 0.1418 - domain_loss: 0.1160 - label_accuracy: 0.9458 - domain_accuracy: 0.6004 - val_loss: 0.4416 - val_label_loss: 0.3262 - val_domain_loss: 0.1155 - val_label_accuracy: 0.9028 - val_domain_accuracy: 0.5908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1971f8160>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, 300, 100)          500000    \n",
      "                                                                 \n",
      " masking_22 (Masking)        (None, 300, 100)          0         \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 298, 64)           19264     \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 59, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 55, 64)            20544     \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 18, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_18 (Gl  (None, 64)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 540,882\n",
      "Trainable params: 540,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Constants\n",
    "vocab_size = 5000  # Same as your BiLSTM model\n",
    "embedding_dim = 100  # Same as your BiLSTM model\n",
    "sequence_length = 300  # Same as your BiLSTM model\n",
    "n_classes = 2  # Binary classification\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture\n",
    "cnn_model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=sequence_length),\n",
    "    Masking(mask_value=0),  # Masking layer\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling1D(pool_size=5),\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "430/430 [==============================] - 77s 173ms/step - loss: 0.4341 - accuracy: 0.8629 - val_loss: 0.3145 - val_accuracy: 0.9016\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 71s 165ms/step - loss: 0.3054 - accuracy: 0.9056 - val_loss: 0.2990 - val_accuracy: 0.9029\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 69s 160ms/step - loss: 0.2722 - accuracy: 0.9160 - val_loss: 0.2898 - val_accuracy: 0.9045\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 69s 160ms/step - loss: 0.2461 - accuracy: 0.9215 - val_loss: 0.2919 - val_accuracy: 0.9068\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 69s 161ms/step - loss: 0.2323 - accuracy: 0.9250 - val_loss: 0.3003 - val_accuracy: 0.9058\n",
      "Epoch 6/50\n",
      "430/430 [==============================] - 69s 160ms/step - loss: 0.2175 - accuracy: 0.9270 - val_loss: 0.2916 - val_accuracy: 0.9025\n",
      "Epoch 7/50\n",
      "430/430 [==============================] - 69s 160ms/step - loss: 0.2079 - accuracy: 0.9270 - val_loss: 0.2965 - val_accuracy: 0.9065\n",
      "Epoch 8/50\n",
      "430/430 [==============================] - 70s 164ms/step - loss: 0.2928 - accuracy: 0.8871 - val_loss: 0.3060 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e299eccc10>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "430/430 [==============================] - 55s 125ms/step - loss: 0.3389 - accuracy: 0.8675 - val_loss: 0.3334 - val_accuracy: 0.9049\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 53s 123ms/step - loss: 0.2437 - accuracy: 0.9131 - val_loss: 0.3110 - val_accuracy: 0.9068\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 54s 126ms/step - loss: 0.2114 - accuracy: 0.9196 - val_loss: 0.2972 - val_accuracy: 0.9045\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 54s 125ms/step - loss: 0.1872 - accuracy: 0.9251 - val_loss: 0.2802 - val_accuracy: 0.9064\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 54s 125ms/step - loss: 0.1673 - accuracy: 0.9305 - val_loss: 0.2743 - val_accuracy: 0.9064\n",
      "Epoch 6/50\n",
      "430/430 [==============================] - 54s 126ms/step - loss: 0.1481 - accuracy: 0.9375 - val_loss: 0.2682 - val_accuracy: 0.9007\n",
      "Epoch 7/50\n",
      "430/430 [==============================] - 54s 125ms/step - loss: 0.1283 - accuracy: 0.9473 - val_loss: 0.2607 - val_accuracy: 0.9013\n",
      "Epoch 8/50\n",
      "430/430 [==============================] - 54s 126ms/step - loss: 0.1126 - accuracy: 0.9550 - val_loss: 0.2641 - val_accuracy: 0.8999\n",
      "Epoch 9/50\n",
      "430/430 [==============================] - 54s 126ms/step - loss: 0.0980 - accuracy: 0.9606 - val_loss: 0.2605 - val_accuracy: 0.9028\n",
      "Epoch 10/50\n",
      "430/430 [==============================] - 54s 125ms/step - loss: 0.0872 - accuracy: 0.9673 - val_loss: 0.2826 - val_accuracy: 0.8846\n",
      "Epoch 11/50\n",
      "430/430 [==============================] - 54s 126ms/step - loss: 0.0716 - accuracy: 0.9739 - val_loss: 0.2754 - val_accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2ab860be0>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "cnn_lstm_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stopping], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "344/344 [==============================] - 7s 20ms/step - loss: 0.7572 - accuracy: 0.7587 - val_loss: 0.4275 - val_accuracy: 0.8777\n",
      "Epoch 2/50\n",
      "344/344 [==============================] - 6s 19ms/step - loss: 0.4677 - accuracy: 0.8538 - val_loss: 0.3964 - val_accuracy: 0.8850\n",
      "Epoch 3/50\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.4437 - accuracy: 0.8592 - val_loss: 0.3967 - val_accuracy: 0.8877\n",
      "Epoch 4/50\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.4241 - accuracy: 0.8661 - val_loss: 0.3841 - val_accuracy: 0.8884\n",
      "Epoch 5/50\n",
      "344/344 [==============================] - 6s 19ms/step - loss: 0.4135 - accuracy: 0.8684 - val_loss: 0.3670 - val_accuracy: 0.8917\n",
      "Epoch 6/50\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.3932 - accuracy: 0.8726 - val_loss: 0.3645 - val_accuracy: 0.8866\n",
      "Epoch 7/50\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.3838 - accuracy: 0.8752 - val_loss: 0.3588 - val_accuracy: 0.8894\n",
      "Epoch 8/50\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.3699 - accuracy: 0.8784 - val_loss: 0.3620 - val_accuracy: 0.8874\n",
      "Epoch 9/50\n",
      "344/344 [==============================] - 6s 19ms/step - loss: 0.3645 - accuracy: 0.8819 - val_loss: 0.3793 - val_accuracy: 0.8695\n",
      "Epoch 10/50\n",
      "344/344 [==============================] - 6s 19ms/step - loss: 0.3491 - accuracy: 0.8843 - val_loss: 0.3628 - val_accuracy: 0.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e290cdf670>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_split=0.2, epochs=50, callbacks=[early_stopping], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_feature(features):\n",
    "    new_features = []\n",
    "    for text in features:\n",
    "        new_text = [x + 1 for x in text]\n",
    "        new_features.append(new_text)\n",
    "    return new_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 5s 86ms/step\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
      " 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
      " 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0\n",
      " 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "test_ids = []\n",
    "test_texts = []\n",
    "# Open file for reading\n",
    "with open('test_set.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        test_ids.append(obj['id'])\n",
    "        test_texts.append(obj['text'])\n",
    "test_texts = update_feature(test_texts)\n",
    "test_features = pad_sequences(test_texts, padding='pre', value=0)\n",
    "import numpy as np\n",
    "# Make predictions\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "# Interpret predictions\n",
    "final_predictions = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0865549e-01, 6.1077189e-02, 2.1181773e-01, ..., 1.3245154e-03,\n",
       "        1.7993655e-03, 3.0141464e-01],\n",
       "       [4.3838033e-03, 3.4897596e-02, 6.6804737e-03, ..., 9.0304613e-01,\n",
       "        8.4550715e-07, 1.5515679e-05],\n",
       "       [2.2277078e-02, 2.8923299e-02, 2.0886326e-02, ..., 4.1087014e-03,\n",
       "        6.7362559e-01, 2.2471841e-01],\n",
       "       ...,\n",
       "       [2.7027252e-04, 5.8505828e-03, 2.5348720e-04, ..., 6.0437560e-05,\n",
       "        9.9267972e-01, 6.0676603e-04],\n",
       "       [1.0504868e-05, 9.0645754e-06, 2.4993237e-06, ..., 1.7466247e-07,\n",
       "        4.1348231e-03, 9.9584204e-01],\n",
       "       [2.3415886e-01, 9.9158414e-02, 2.4144238e-01, ..., 1.7545497e-03,\n",
       "        6.5056491e-04, 1.7444958e-01]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_df = pd.DataFrame({\"id\":test_ids, \"class\": final_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 1s 20ms/step\n",
      "[0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ensemble_predictions(models, x_test):\n",
    "    # Get predictions from each model\n",
    "    preds = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # Average the predictions\n",
    "    avg_preds = np.mean(preds, axis=0)\n",
    "    \n",
    "    final_predictions = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "    \n",
    "    return  final_predictions \n",
    "\n",
    "# Example usage\n",
    "models = [cnn_model, bilstm_model]  # Assuming cnn_model and bilstm_model are your trained models\n",
    "ensemble_preds = ensemble_predictions(models, test_features)\n",
    "\n",
    "print(ensemble_preds)  # Output should be like [0, 1, 1, 1, ...]\n",
    "\n",
    "output_df = pd.DataFrame({\"id\":test_ids, \"class\": ensemble_preds})\n",
    "output_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
