{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Masking\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "features_d1 = []\n",
    "labels_d1 = []\n",
    "# Open file for reading\n",
    "with open('domain1_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d1.append(obj['text'])\n",
    "        labels_d1.append(obj['label'])\n",
    "features_d2 = []\n",
    "labels_d2 = []\n",
    "# Open file for reading\n",
    "with open('domain2_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        features_d2.append(obj['text'])\n",
    "        labels_d2.append(obj['label'])\n",
    "features = features_d1 + features_d2\n",
    "labels = labels_d1 + labels_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = pad_sequences(features, padding='pre', maxlen=150, value=-1)\n",
    "labels = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27520"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000  # Adjust based on your actual vocabulary size\n",
    "embedding_dim = 128\n",
    "sequence_length = 150\n",
    "n_classes = 2  # Binary classification\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Masking, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, Flatten, AdditiveAttention, GlobalAveragePooling1D\n",
    "from keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Include early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=sequence_length),\n",
    "    Masking(mask_value=-1),  # Usually 0 is used for padding\n",
    "    Conv1D(64, 5, activation='relu', kernel_regularizer=l2(0.001)),  # Reduced number of filters and regularization\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(5),\n",
    "    Dropout(0.5),  # Increased dropout rate\n",
    "    Bidirectional(LSTM(32, recurrent_regularizer=l2(0.001), kernel_regularizer=l2(0.001))),  # Reduced LSTM units\n",
    "    Dropout(0.5),  # Increased dropout rate\n",
    "    Dense(n_classes, activation='sigmoid', kernel_regularizer=l1(0.001))  # Reduced regularization and activation changed to sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "688/688 [==============================] - 19s 22ms/step - loss: 0.5077 - accuracy: 0.8824 - val_loss: 0.3966 - val_accuracy: 0.8975\n",
      "Epoch 2/50\n",
      "688/688 [==============================] - 11s 16ms/step - loss: 0.3410 - accuracy: 0.9090 - val_loss: 0.3436 - val_accuracy: 0.9026\n",
      "Epoch 3/50\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.2905 - accuracy: 0.9190 - val_loss: 0.3543 - val_accuracy: 0.8972\n",
      "Epoch 4/50\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.2561 - accuracy: 0.9276 - val_loss: 0.3621 - val_accuracy: 0.8937\n",
      "Epoch 5/50\n",
      "688/688 [==============================] - 11s 16ms/step - loss: 0.2254 - accuracy: 0.9394 - val_loss: 0.3780 - val_accuracy: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b215ac670>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "test_texts = []\n",
    "# Open file for reading\n",
    "with open('test_set.json', 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse the JSON line into a Python dictionary\n",
    "        obj = json.loads(line)\n",
    "        test_ids.append(obj['id'])\n",
    "        test_texts.append(obj['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
