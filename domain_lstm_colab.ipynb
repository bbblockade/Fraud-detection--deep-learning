{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z9zUpwKHD2H7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14900"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Masking\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "features_d1 = []\n",
        "labels_d1 = []\n",
        "labels_domain = []\n",
        "features_human_d1 = []\n",
        "zeros_in_text_d1 = []\n",
        "# Open file for reading\n",
        "with open('domain1_train.json', 'r') as f:\n",
        "    for line in f:\n",
        "        # Parse the JSON line into a Python dictionary\n",
        "        obj = json.loads(line)\n",
        "        labels_d1.append(obj['label'])\n",
        "        text_without_zeros = []\n",
        "        count_zeros = 0\n",
        "        for id in obj['text']:\n",
        "            if id != 0 :\n",
        "                text_without_zeros.append(id)\n",
        "            else:\n",
        "                count_zeros += 1\n",
        "        features_d1.append(text_without_zeros)\n",
        "        zeros_in_text_d1.append(count_zeros)\n",
        "        labels_domain.append(0)\n",
        "        if obj['label'] == 1:\n",
        "            features_human_d1.append(text_without_zeros)\n",
        "\n",
        "features_d2 = []\n",
        "labels_d2 = []\n",
        "domains_d2 = []\n",
        "features_human_d2 = []\n",
        "zeros_in_text_d2 = []\n",
        "# Open file for reading\n",
        "with open('domain2_train.json', 'r') as f:\n",
        "    for line in f:\n",
        "        # Parse the JSON line into a Python dictionary\n",
        "        obj = json.loads(line)\n",
        "        text_without_zeros = []\n",
        "        count_zeros = 0\n",
        "        for id in obj['text']:\n",
        "            if id != 0 :\n",
        "                text_without_zeros.append(id)\n",
        "            else:\n",
        "                count_zeros += 1\n",
        "        features_d2.append(text_without_zeros)\n",
        "        zeros_in_text_d2.append(count_zeros)\n",
        "        labels_d2.append(obj['label'])\n",
        "        labels_domain.append(1)\n",
        "        if obj['label'] == 1:\n",
        "            domains_d2.append(7)\n",
        "            features_human_d2.append(text_without_zeros)\n",
        "        else:\n",
        "            domains_d2.append(int(obj['model']))\n",
        "len(features_human_d2)\n",
        "len(features_d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(3000):\n",
        "    features_human_d2.append(features_d1[i]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5150"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features_human_d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "len_features_human_d1= [len(x) for x in features_human_d1] \n",
        "len_features_human_d2= [len(x) for x in features_human_d2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([3771.,  534.,  396.,   76.,   87.,   80.,   60.,   69.,   46.,\n",
              "          31.]),\n",
              " array([  0. ,  85.2, 170.4, 255.6, 340.8, 426. , 511.2, 596.4, 681.6,\n",
              "        766.8, 852. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(len_features_human_d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 620., 3328., 2996., 1778.,  671.,  234.,   70.,   38.,    6.,\n",
              "           9.]),\n",
              " array([ 0. ,  9.1, 18.2, 27.3, 36.4, 45.5, 54.6, 63.7, 72.8, 81.9, 91. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(len_features_human_d1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Convert features and labels into a single DataFrame for easier handling\n",
        "df = pd.DataFrame({\n",
        "    'features': features_d2,\n",
        "    'labels': labels_d2\n",
        "})\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df[df.labels==0]\n",
        "df_minority = df[df.labels==1]\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=len(df_minority),  # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Split the DataFrame back into features and labels\n",
        "features_downsampled = df_downsampled['features'].tolist()\n",
        "labels_downsampled = df_downsampled['labels'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p3MS7b5uD2H-"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "features = features_d1+features_d2\n",
        "labels = labels_d1 + labels_d2\n",
        "zeros_in_text = zeros_in_text_d1 + zeros_in_text_d2\n",
        "padded_features = pad_sequences(features, padding='pre', value=0)\n",
        "labels_domain = to_categorical(labels_domain, num_classes=2)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, zeros_train, zeros_test,= train_test_split(\n",
        "    padded_features, labels_domain, zeros_in_text,   test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "padded_features_d1 = pad_sequences(features_d1, padding='pre', value=0)\n",
        "labels_d1 = to_categorical(labels_d1, num_classes=2)\n",
        "X_train_domain1, X_test_domain1, y_train_domain1, y_test_domain1, zeros_train_d1, zeros_test_d1 = train_test_split(\n",
        "    padded_features_d1, labels_d1, zeros_in_text_d1, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "padded_features_d2 = pad_sequences(features_d2, padding='pre', value=0)\n",
        "labels_d2 = to_categorical(labels_d2, num_classes=2)\n",
        "domains_d2 = to_categorical(domains_d2, num_classes=8)\n",
        "\n",
        "X_train_domain2, X_test_domain2, zeros_train_d2, zeros_test_d2, y_train_domain2, y_test_domain2, y_model_train, y_model_test = train_test_split(\n",
        "    padded_features_d2, zeros_in_text_d2, labels_d2,domains_d2, test_size=0.2, random_state=42, stratify=labels_d2)\n",
        "\n",
        "y_train_d2 = {'class': y_train_domain2, 'model': y_model_train}\n",
        "y_test_d2 = {'class': y_test_domain2, 'model': y_model_test}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCsAapweD2H_",
        "outputId": "6988fcc5-b361-4416-9bf0-5e2790e055a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 100)    500000      ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 128)         84480       ['embedding_5[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 128)          0           ['bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 129)          0           ['dropout_13[0][0]',             \n",
            "                                                                  'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           4160        ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 32)           0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " domain (Dense)                 (None, 2)            66          ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 588,706\n",
            "Trainable params: 588,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout, Masking, Input, Bidirectional, concatenate\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "# Constants\n",
        "vocab_size = 5000  # Vocabulary size\n",
        "embedding_dim = 100 # Embedding dimension\n",
        "n_domain_classes = 2 # Classification for the domain task\n",
        "n_classes = 2\n",
        "# Input Layer\n",
        "input_layer = Input(shape=(None,))\n",
        "# New Input Layer for the integer feature\n",
        "input_layer_integer = Input(shape=(1,)) \n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Conv1D Layer\n",
        "#conv1d_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding_layer)\n",
        "\n",
        "# Dropout Layer\n",
        "#dropout_conv = Dropout(0.3)(conv1d_layer)\n",
        "\n",
        "\n",
        "# Max Pooling Layer\n",
        "#max_pooling = MaxPooling1D(pool_size=2)(dropout_conv)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = Bidirectional(LSTM(64))(embedding_layer)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_lstm = Dropout(0.3)(lstm_layer)\n",
        "\n",
        "# Concatenate integer input with LSTM output\n",
        "concat_layer = concatenate([dropout_lstm, input_layer_integer])\n",
        "\n",
        "# New Dense Layer\n",
        "dense_layer = Dense(32, activation='relu')(concat_layer)\n",
        "dense_dropout = Dropout(0.3)(dense_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Domain output\n",
        "domain_output = Dense(n_domain_classes, activation='sigmoid', name='domain')(dense_dropout)\n",
        "\n",
        "\n",
        "# Combined model\n",
        "model_domain = Model(inputs=[input_layer, input_layer_integer], outputs= domain_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_domain.compile(optimizer='adam',\n",
        "              loss={\n",
        "                  'domain': 'binary_crossentropy'},\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Model summary\n",
        "model_domain.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Yu7fxPD2IA",
        "outputId": "959c0748-2ebe-4cd8-9a2d-6686bb792352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 7/54 [==>...........................] - ETA: 4:31 - loss: 0.6831 - accuracy: 0.4852"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\domain_lstm_colab.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m zeros_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(zeros_train)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m zeros_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(zeros_test)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_domain\u001b[39m.\u001b[39;49mfit([X_train,zeros_train], y_train, validation_data\u001b[39m=\u001b[39;49m([X_test, zeros_test], y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "zeros_train = np.array(zeros_train).reshape(-1, 1)\n",
        "zeros_test = np.array(zeros_test).reshape(-1, 1)\n",
        "model_domain.fit([X_train,zeros_train], y_train, validation_data=([X_test, zeros_test], y_test), epochs=50, callbacks=[early_stopping], batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_domain\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_domain\\assets\n"
          ]
        }
      ],
      "source": [
        "model_domain.save(\"model_domain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDCM3pykD2IB",
        "outputId": "c1695f2b-1479-4f0f-b06e-6cdd7fb7d972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, None, 100)    500000      ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, 128)         84480       ['embedding_6[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 128)          0           ['bidirectional_5[0][0]']        \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 129)          0           ['dropout_15[0][0]',             \n",
            "                                                                  'input_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 32)           4160        ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 32)           0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 2)            66          ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 588,706\n",
            "Trainable params: 588,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "vocab_size = 5000  # Vocabulary size\n",
        "embedding_dim = 100 # Embedding dimension\n",
        "n_domain_classes = 2 # Classification for the domain task\n",
        "\n",
        "# Input Layer\n",
        "input_layer = Input(shape=(None,))\n",
        "\n",
        "input_layer_integer = Input(shape=(1,)) \n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
        "\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = Bidirectional(LSTM(64))(embedding_layer)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_lstm = Dropout(0.3)(lstm_layer)\n",
        "\n",
        "# Concatenate integer input with LSTM output\n",
        "concat_layer = concatenate([dropout_lstm, input_layer_integer])\n",
        "\n",
        "# New Dense Layer\n",
        "dense_layer = Dense(32, activation='relu')(concat_layer)\n",
        "dense_dropout = Dropout(0.3)(dense_layer)\n",
        "\n",
        "\n",
        "# Domain output\n",
        "class_output = Dense(n_domain_classes, activation='sigmoid')(dense_dropout)\n",
        "\n",
        "# Combined model\n",
        "model_domain1 = Model(inputs=[input_layer, input_layer_integer], outputs=class_output)\n",
        "\n",
        "\n",
        "\n",
        "model_domain1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Model summary\n",
        "model_domain1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkXtuhH6D2IB",
        "outputId": "caa95bcc-1ec1-4a48-dcad-48638e3c0184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "61/61 [==============================] - 84s 1s/step - loss: 0.4575 - accuracy: 0.7776 - val_loss: 0.1958 - val_accuracy: 0.9300\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 72s 1s/step - loss: 0.1634 - accuracy: 0.9492 - val_loss: 0.1457 - val_accuracy: 0.9469\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 74s 1s/step - loss: 0.0970 - accuracy: 0.9710 - val_loss: 0.1419 - val_accuracy: 0.9479\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 74s 1s/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 0.1714 - val_accuracy: 0.9477\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 77s 1s/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.1771 - val_accuracy: 0.9497\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 74s 1s/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.1966 - val_accuracy: 0.9536\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1dcfac51cd0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "zeros_train_d1 = np.array(zeros_train_d1).reshape(-1, 1)\n",
        "zeros_test_d1 = np.array(zeros_test_d1).reshape(-1, 1)\n",
        "model_domain1.fit([X_train_domain1,zeros_train_d1], y_train_domain1, validation_data=([X_test_domain1,zeros_test_d1], y_test_domain1), epochs=50, callbacks=[early_stopping], batch_size = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_domain1\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_domain1\\assets\n"
          ]
        }
      ],
      "source": [
        "model_domain1.save(\"model_domain1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNmAeA2BEHuf",
        "outputId": "f45081af-3583-474f-f7f6-ea1a0585bea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 100)    500000      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, None, 64)     19264       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 64)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           33024       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           2080        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " class (Dense)                  (None, 2)            66          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " model (Dense)                  (None, 8)            264         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 554,698\n",
            "Trainable params: 554,698\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "vocab_size = 5000  # Vocabulary size\n",
        "embedding_dim = 100 # Embedding dimension\n",
        "n_models = 8  # Classification for the domain task\n",
        "n_classes =2 \n",
        "# Input Layer\n",
        "input_layer = Input(shape=(None,))\n",
        "\n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer)\n",
        "\n",
        "# Conv1D Layer\n",
        "conv1d_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding_layer)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_conv = Dropout(0.3)(conv1d_layer)\n",
        "\n",
        "\n",
        "# Max Pooling Layer\n",
        "max_pooling = MaxPooling1D(pool_size=2)(dropout_conv)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = (LSTM(64))(dropout_conv)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_lstm = Dropout(0.3)(lstm_layer)\n",
        "\n",
        "\n",
        "# New Dense Layer\n",
        "dense_layer = Dense(32, activation='relu')(dropout_lstm)\n",
        "dense_dropout = Dropout(0.3)(dense_layer)\n",
        "\n",
        "\n",
        "class_output = Dense(n_classes, activation='sigmoid', name='class')(dense_dropout)\n",
        "\n",
        "\n",
        "\n",
        "model_output = Dense(n_models, activation='softmax', name='model')(dense_dropout)\n",
        "\n",
        "# Combined model\n",
        "model_domain2 = Model(inputs=input_layer, outputs=[class_output, model_output])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_domain2.compile(optimizer='adam',\n",
        "              loss={\n",
        "                  'class': weighted_binary_crossentropy,\n",
        "                  'model': 'categorical_crossentropy'},\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Model summary\n",
        "model_domain2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27520"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train_d2[\"class\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights (this is just an example; you'll need to compute this based on your own data)\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=np.argmax(y_train_domain2, axis=1) )  # your_labels is the array of labels in your training set\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    weight_0 = class_weight_dict[0]\n",
        "    weight_1 = class_weight_dict[1]\n",
        "    \n",
        "    binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = binary_crossentropy(y_true, y_pred)\n",
        "    class_weights = y_true * weight_1 + (1. - y_true) * weight_0\n",
        "    weighted_loss = loss * class_weights\n",
        "    \n",
        "    return tf.reduce_mean(weighted_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 100)    500000      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, None, 64)     19264       ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, None, 64)     0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 64)           33024       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 64)           0           ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 65)           0           ['dropout_7[0][0]',              \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           2112        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " class (Dense)                  (None, 2)            66          ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " model (Dense)                  (None, 8)            264         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 554,730\n",
            "Trainable params: 554,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Constants\n",
        "vocab_size = 5000  # Vocabulary size\n",
        "embedding_dim = 100  # Embedding dimension\n",
        "n_models = 8  # Classification for the domain task\n",
        "n_classes = 2  # Number of classes\n",
        "\n",
        "# Existing Input Layer for text\n",
        "input_layer_text = Input(shape=(None,))\n",
        "\n",
        "# New Input Layer for the integer feature\n",
        "input_layer_integer = Input(shape=(1,))  # Change shape as necessary\n",
        "\n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True)(input_layer_text)\n",
        "\n",
        "# Conv1D Layer\n",
        "conv1d_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding_layer)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_conv = Dropout(0.3)(conv1d_layer)\n",
        "\n",
        "# Max Pooling Layer\n",
        "max_pooling = MaxPooling1D(pool_size=2)(dropout_conv)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = LSTM(64)(dropout_conv)\n",
        "\n",
        "# Dropout Layer\n",
        "dropout_lstm = Dropout(0.3)(lstm_layer)\n",
        "\n",
        "# Concatenate integer input with LSTM output\n",
        "concat_layer = concatenate([dropout_lstm, input_layer_integer])\n",
        "\n",
        "# New Dense Layer\n",
        "dense_layer = Dense(32, activation='relu')(concat_layer)\n",
        "dense_dropout = Dropout(0.3)(dense_layer)\n",
        "\n",
        "# Class output layer\n",
        "class_output = Dense(n_classes, activation='sigmoid', name='class')(dense_dropout)\n",
        "\n",
        "# Model output layer\n",
        "model_output = Dense(n_models, activation='softmax', name='model')(dense_dropout)\n",
        "\n",
        "# Combined model\n",
        "model_domain2 = Model(inputs=[input_layer_text, input_layer_integer], outputs=[class_output, model_output])\n",
        "\n",
        "# Compile the model\n",
        "model_domain2.compile(optimizer='adam',\n",
        "                      loss={\n",
        "                          'class': weighted_binary_crossentropy,  # Replace with your weighted loss if needed\n",
        "                          'model': 'categorical_crossentropy'},\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model_domain2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'class': array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]], dtype=float32),\n",
              " 'model': array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_d2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyQLya8qEJVm",
        "outputId": "48c713fa-2684-47fe-d7ef-75c69a34f521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 11s 120ms/step - loss: 4.0402 - class_loss: 1.5027 - model_loss: 2.5375 - class_accuracy: 0.8371 - model_accuracy: 0.1579 - val_loss: 2.8997 - val_class_loss: 0.9787 - val_model_loss: 1.9210 - val_class_accuracy: 0.8557 - val_model_accuracy: 0.1980\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 3.2647 - class_loss: 1.0584 - model_loss: 2.2063 - class_accuracy: 0.8467 - model_accuracy: 0.1890 - val_loss: 2.6820 - val_class_loss: 0.8013 - val_model_loss: 1.8807 - val_class_accuracy: 0.8557 - val_model_accuracy: 0.2450\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 2.9043 - class_loss: 0.8961 - model_loss: 2.0082 - class_accuracy: 0.8529 - model_accuracy: 0.2292 - val_loss: 2.5725 - val_class_loss: 0.7700 - val_model_loss: 1.8025 - val_class_accuracy: 0.8560 - val_model_accuracy: 0.2668\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 5s 106ms/step - loss: 2.6696 - class_loss: 0.7872 - model_loss: 1.8824 - class_accuracy: 0.8605 - model_accuracy: 0.2633 - val_loss: 2.5463 - val_class_loss: 0.7728 - val_model_loss: 1.7735 - val_class_accuracy: 0.8550 - val_model_accuracy: 0.2708\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 2.4753 - class_loss: 0.6898 - model_loss: 1.7855 - class_accuracy: 0.8694 - model_accuracy: 0.2969 - val_loss: 2.6315 - val_class_loss: 0.8487 - val_model_loss: 1.7829 - val_class_accuracy: 0.8577 - val_model_accuracy: 0.2758\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 5s 102ms/step - loss: 2.3407 - class_loss: 0.6194 - model_loss: 1.7212 - class_accuracy: 0.8785 - model_accuracy: 0.3099 - val_loss: 2.6210 - val_class_loss: 0.8464 - val_model_loss: 1.7746 - val_class_accuracy: 0.8470 - val_model_accuracy: 0.2768\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 2.2335 - class_loss: 0.5665 - model_loss: 1.6669 - class_accuracy: 0.8892 - model_accuracy: 0.3313 - val_loss: 2.6620 - val_class_loss: 0.8818 - val_model_loss: 1.7803 - val_class_accuracy: 0.8477 - val_model_accuracy: 0.2899\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 2.1273 - class_loss: 0.4971 - model_loss: 1.6302 - class_accuracy: 0.9010 - model_accuracy: 0.3444 - val_loss: 2.7842 - val_class_loss: 0.9694 - val_model_loss: 1.8148 - val_class_accuracy: 0.8426 - val_model_accuracy: 0.2883\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 2.0123 - class_loss: 0.4365 - model_loss: 1.5758 - class_accuracy: 0.9170 - model_accuracy: 0.3666 - val_loss: 2.8995 - val_class_loss: 1.0519 - val_model_loss: 1.8476 - val_class_accuracy: 0.8329 - val_model_accuracy: 0.2987\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 1.8959 - class_loss: 0.3665 - model_loss: 1.5294 - class_accuracy: 0.9299 - model_accuracy: 0.3781 - val_loss: 3.0353 - val_class_loss: 1.1386 - val_model_loss: 1.8967 - val_class_accuracy: 0.8171 - val_model_accuracy: 0.2946\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 1.7873 - class_loss: 0.3075 - model_loss: 1.4798 - class_accuracy: 0.9463 - model_accuracy: 0.3914 - val_loss: 3.2560 - val_class_loss: 1.2700 - val_model_loss: 1.9860 - val_class_accuracy: 0.8258 - val_model_accuracy: 0.3037\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 1.6860 - class_loss: 0.2562 - model_loss: 1.4298 - class_accuracy: 0.9576 - model_accuracy: 0.4061 - val_loss: 3.5232 - val_class_loss: 1.4393 - val_model_loss: 2.0838 - val_class_accuracy: 0.8091 - val_model_accuracy: 0.2977\n",
            "Epoch 13/50\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 1.5981 - class_loss: 0.2041 - model_loss: 1.3940 - class_accuracy: 0.9697 - model_accuracy: 0.4189"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\chenj\\Documents\\SML\\ass1\\SML-assignment\\domain_lstm_colab.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m zeros_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(zeros_test)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chenj/Documents/SML/ass1/SML-assignment/domain_lstm_colab.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_domain2\u001b[39m.\u001b[39;49mfit([X_train_domain2,zeros_train], y_train_d2, validation_data\u001b[39m=\u001b[39;49m([X_test_domain2,zeros_test], y_test_d2), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping], batch_size \u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
            "File \u001b[1;32mc:\\Users\\chenj\\anaconda3\\envs\\CV\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "zeros_train = np.array(zeros_train).reshape(-1, 1)\n",
        "zeros_test = np.array(zeros_test).reshape(-1, 1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_domain2.fit([X_train_domain2,zeros_train], y_train_d2, validation_data=([X_test_domain2,zeros_test], y_test_d2), epochs=50, callbacks=[early_stopping], batch_size = 256)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
